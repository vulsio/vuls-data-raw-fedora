{
	"alias": "FEDORA-2015-1892",
	"bugs": [
		{
			"bug_id": 1168672,
			"title": "\"libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\\\x2dinstance\\\\x2d00000002.scope/cpuset.mems': Device or resource busy\"",
			"bugzilla": {
				"bug_id": "1168672",
				"creation_ts": "2014-11-27 14:48:28 +0000",
				"short_desc": "\"libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\"",
				"delta_ts": "2015-02-15 03:06:21 +0000",
				"bug_status": "CLOSED",
				"resolution": "ERRATA",
				"keywords": "Reopened, Upstream",
				"priority": "unspecified",
				"bug_severity": "unspecified",
				"blocked": [
					{
						"bug_id": "1168866",
						"creation_ts": "2014-11-28 09:41:19 +0000",
						"short_desc": "\"libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\"",
						"delta_ts": "2015-03-05 07:47:47 +0000",
						"bug_status": "CLOSED",
						"resolution": "ERRATA",
						"keywords": "Upstream",
						"priority": "unspecified",
						"bug_severity": "medium",
						"depends_on": [
							"1168672",
							"1168944"
						],
						"external_bugs": {
							"text": "RHSA-2015:0323",
							"name": "Red Hat Product Errata"
						},
						"long_desc": [
							{
								"isprivate": "0",
								"commentid": "7716124",
								"comment_count": "0",
								"who": {
									"text": "jsuchane",
									"name": "Jaroslav Suchanek"
								},
								"bug_when": "2014-11-28 09:41:19 +0000",
								"thetext": "+++ This bug was initially created as a clone of Bug #1168672 +++\n\nDescription of problem\n----------------------\n\nThis occurs when you boot a Nova instance with NUMA topology.\n\n[. . .]\nlibvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .'\n\nVersion\n-------\n\nVersions of libvirt, QEMU, systemd in the OpenStack setup (running in a\nDevStack VM):\n\n  $ uname -r; rpm -q libvirt-daemon-kvm qemu-system-x86 systemd\n  3.18.0-0.rc6.git0.1.fc22.x86_64\n  libvirt-daemon-kvm-1.2.10-3.fc22.x86_64\n  qemu-system-x86-2.2.0-0.1.rc1.fc22.x86_64\n  systemd-216-11.fc21.x86_64\n\n\nHow reproducible: Atleast twice.\n\n\nSteps to reproduce\n------------------\n\nThis occurred in when booting a Nova instance in a DevStack (OpenStack\ndeveloper setup) environment. The DevStack machine is a KVM guest\nhypervisor, and the Nova guest is a nested guest running on this.\n\nIt's a fairly involved test environment, details here:\n\nhttp://docs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\ndocs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\n\n\nActual results\n--------------\n\n[. . .]\n2014-11-26 20:17:28.722 ERROR nova.compute.manager [-] [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Instance failed to spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Traceback (most recent call last):\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2247, in _build_resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     yield resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2117, in _build_and_run_instance\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     instance_type=instance_type)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/li\nbvirt/driver.py\", line 2640, in spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     block_device_info, disk_info=disk_info)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4500, in _create_domain_and_network\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     power_on=power_on)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4433, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     LOG.error(err)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/oslo/utils/excutils.py\", line 82, in __exit__\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(self.type_, self.value, self.tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4423, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     domain.createWithFlags(launch_flags)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = execute(f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(c, e, tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = meth(*args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 1033, in createWithFlags\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .]\n\n\nExpected results\n----------------\n\nNova instance (libvirt nested guest) should boot successfully.\n\n\nAdditional info\n---------------\n\n[1] Inventory of available NUMA nodes on the physical host:\n\n$ numactl --hardware\navailable: 4 nodes (0-3)\nnode 0 cpus: 0 4 8 12 16 20 24 28 32 36 40 44\nnode 0 size: 257954 MB\nnode 0 free: 248486 MB\nnode 1 cpus: 1 5 9 13 17 21 25 29 33 37 41 45\nnode 1 size: 258045 MB\nnode 1 free: 256470 MB\nnode 2 cpus: 2 6 10 14 18 22 26 30 34 38 42 46\nnode 2 size: 258045 MB\nnode 2 free: 256507 MB\nnode 3 cpus: 3 7 11 15 19 23 27 31 35 39 43 47\nnode 3 size: 258040 MB\nnode 3 free: 256457 MB\nnode distances:\nnode   0   1   2   3 \n  0:  10  20  20  20 \n  1:  20  10  20  20 \n  2:  20  20  10  20 \n  3:  20  20  20  10 \n\n[2] From sytemd `journactl`:\n\n$ sudo journalctl -u libvirtd -l -p err\n[. . .]\nNov 26 09:19:49 devstack libvirtd[32697]: driver in virRegisterStorageDriver must not be NULL\nNov 26 09:19:49 devstack libvirtd[32697]: Failed module registration vboxStorageRegister\nNov 26 10:33:51 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 11:12:36 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 20:17:28 devstack libvirtd[32697]: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\nNov 26 20:17:28 devstack libvirtd[32697]: error from service: TerminateMachine: No machine 'qemu-instance-00000002' known\n[. . .]\n\n\n[3] From an existing Nova instance (that was booted _without_ NUMA)\n\n    $ find /sys/fs/cgroup/cpuset/machine.slice/machine-qemu*/ -name cpuset.mems \n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/vcpu0/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/emulator/cpuset.mems\n    \n    $ cd /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\\\x2dinstance\\\\x2d00000001.scope/\n    $ cat cpuset.mems vcpu0/cpuset.mems emulator/cpuset.mems \n    0-2\n    0-2\n    0-2\n\n\n[4] libvirt developer Martin Kletzander confirmed on IRC (#virt, OFTC) that\nthis is a bug.\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:16:02 EST ---\n\nContextual snippet related to cgroups from the attached libvirtd debug log:\n\n[. . .]\n2014-11-27 14:18:20.835+0000: 25475: debug : virCgroupSetValueStr:718 : Set value '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems' to '0'\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 25\n2014-11-27 14:18:20.836+0000: 25475: error : virCgroupSetValueStr:728 : Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems': Device or resource busy\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 24\n[. . .]\n2014-11-27 14:18:21.041+0000: 25475: debug : virDBusMessageIterEncode:640 : Popping iter=0x7fd43ef944d0\n2014-11-27 14:18:21.042+0000: 25475: error : virDBusCall:1537 : error from service: TerminateMachine: No machine 'qemu-instance-00000003' known\n2014-11-27 14:18:21.042+0000: 25475: debug : qemuRemoveCgroup:1222 : Failed to terminate cgroup for instance-00000003\n2014-11-27 14:18:21.042+0000: 25475: debug : virObjectUnref:259 : OBJECT_UNREF: obj=0x7fd4300e6890\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3331 : Removing cgroup /machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemoveRecursively:3302 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope//emulator\n[. . .]\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:28:09 EST ---\n\nDevStack machine's capabilities where the Nova Compute service is running and a libvirt instance (a nested guest) failed to started)\n\n---------------------\nDevStack>$ virsh capabilities\n<capabilities>\n\n  <host>\n    <uuid>7dae2ee3-8950-9a41-9e24-a463a8563bbd</uuid>\n    <cpu>\n      <arch>x86_64</arch>\n      <model>Nehalem</model>\n      <vendor>Intel</vendor>\n      <topology sockets='1' cores='8' threads='1'/>\n      <feature name='rdtscp'/>\n      <feature name='hypervisor'/>\n      <feature name='x2apic'/>\n      <feature name='vmx'/>\n      <feature name='ss'/>\n      <feature name='vme'/>\n      <pages unit='KiB' size='4'/>\n      <pages unit='KiB' size='2048'/>\n    </cpu>\n    <power_management>\n      <suspend_mem/>\n      <suspend_disk/>\n      <suspend_hybrid/>\n    </power_management>\n    <migration_features>\n      <live/>\n      <uri_transports>\n        <uri_transport>tcp</uri_transport>\n        <uri_transport>rdma</uri_transport>\n      </uri_transports>\n    </migration_features>\n    <topology>\n      <cells num='3'>\n        <cell id='0'>\n          <memory unit='KiB'>3949740</memory>\n          <pages unit='KiB' size='4'>987435</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='10'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='4'>\n            <cpu id='0' socket_id='0' core_id='0' siblings='0'/>\n            <cpu id='1' socket_id='1' core_id='0' siblings='1'/>\n            <cpu id='2' socket_id='2' core_id='0' siblings='2'/>\n            <cpu id='3' socket_id='3' core_id='0' siblings='3'/>\n          </cpus>\n        </cell>\n        <cell id='1'>\n          <memory unit='KiB'>2016864</memory>\n          <pages unit='KiB' size='4'>504216</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='10'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='4' socket_id='4' core_id='0' siblings='4'/>\n            <cpu id='5' socket_id='5' core_id='0' siblings='5'/>\n          </cpus>\n        </cell>\n        <cell id='2'>\n          <memory unit='KiB'>2014304</memory>\n          <pages unit='KiB' size='4'>503576</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='10'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='6' socket_id='6' core_id='0' siblings='6'/>\n            <cpu id='7' socket_id='7' core_id='0' siblings='7'/>\n          </cpus>\n        </cell>\n      </cells>\n    </topology>\n    <secmodel>\n      <model>selinux</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>system_u:system_r:svirt_t:s0</baselabel>\n      <baselabel type='qemu'>system_u:system_r:svirt_tcg_t:s0</baselabel>\n    </secmodel>\n    <secmodel>\n      <model>dac</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>+107:+107</baselabel>\n      <baselabel type='qemu'>+107:+107</baselabel>\n    </secmodel>\n  </host>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='i686'>\n      <wordsize>32</wordsize>\n      <emulator>/usr/bin/qemu-system-i386</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n      <pae/>\n      <nonpae/>\n    </features>\n  </guest>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='x86_64'>\n      <wordsize>64</wordsize>\n      <emulator>/usr/bin/qemu-system-x86_64</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n    </features>\n  </guest>\n\n</capabilities>\n---------------------\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:29:07 EST ---\n\n\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:33:39 EST ---\n\nContextual snippet from the attachment:\n\n[. . .]\n  <memory>1048576</memory>\n  <numatune>\n    <memory mode=\"strict\" nodeset=\"0\"/>\n    <memnode cellid=\"0\" mode=\"strict\" nodeset=\"0\"/>\n  </numatune>\n  <vcpu>4</vcpu>\n  <metadata>\n    <nova:instance xmlns:nova=\"http://openstack.org/xmlns/libvirt/nova/1.0\">\n      <nova:package version=\"2015.1\"/>\n      <nova:name>cirrvm3</nova:name>\n      <nova:creationTime>2014-11-27 14:18:18</nova:creationTime>\n      <nova:flavor name=\"m1.numa\">\n        <nova:memory>1024</nova:memory>\n        <nova:disk>1</nova:disk>\n        <nova:swap>0</nova:swap>\n        <nova:ephemeral>0</nova:ephemeral>\n        <nova:vcpus>4</nova:vcpus>\n      </nova:flavor>\n      <nova:owner>\n        <nova:user uuid=\"e2ab0e48d003456da53e892366651175\">admin</nova:user>\n        <nova:project uuid=\"a9a2cd5511214089a290ccfcac47502c\">admin</nova:project>\n      </nova:owner>\n      <nova:root type=\"image\" uuid=\"178c675a-d5fb-459f-a850-f7ffa6e2c9d2\"/>\n    </nova:instance>\n  </metadata>\n[. . .]\n  <cputune>\n    <emulatorpin cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"0\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"1\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"2\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"3\" cpuset=\"0-3\"/>\n  </cputune>\n[. . .]\n\n--- Additional comment from Nikola Dipanov on 2014-11-27 12:10:46 EST ---\n\nIt might also be relevant that in this case, the domain XML will as well have a <numa> element specified."
							},
							{
								"isprivate": "0",
								"commentid": "7716838",
								"comment_count": "1",
								"who": {
									"text": "mkletzan",
									"name": "Martin Kletzander"
								},
								"bug_when": "2014-11-28 13:32:42 +0000",
								"thetext": "Fixed upstream with v1.2.10-75-gc6e9024:\n\ncommit c6e90248676126c209b3b6017ad27cf6c6a0ab8f\nAuthor: Wang Rui <moon.wangrui@huawei.com>\nDate:   Mon Nov 10 21:53:19 2014 +0800\n\n    qemu: fix domain startup failing with 'strict' mode in numatune"
							},
							{
								"isprivate": "0",
								"commentid": "7716955",
								"comment_count": "3",
								"who": {
									"text": "kchamart",
									"name": "Kashyap Chamarthy"
								},
								"bug_when": "2014-11-28 14:13:24 +0000",
								"thetext": "*** Bug 1168944 has been marked as a duplicate of this bug. ***"
							},
							{
								"isprivate": "0",
								"commentid": "7749668",
								"comment_count": "5",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-10 08:01:24 +0000",
								"thetext": "*** Bug 1118517 has been marked as a duplicate of this bug. ***"
							},
							{
								"isprivate": "0",
								"commentid": "7754214",
								"comment_count": "6",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-11 08:16:35 +0000",
								"thetext": "Hi Kashyap，\n\nI am libvirt qe, and trying to reproduce this bug on RHEL7.\nCould you meet this problem on RHEL7? Is nested KVM necessary for this bug?"
							},
							{
								"isprivate": "0",
								"commentid": "7754410",
								"comment_count": "7",
								"who": {
									"text": "kchamart",
									"name": "Kashyap Chamarthy"
								},
								"bug_when": "2014-12-11 09:14:45 +0000",
								"thetext": "(In reply to Jincheng Miao from comment #6)\n> Hi Kashyap，\n\nHi Jincheng,\n\n> \n> I am libvirt qe, and trying to reproduce this bug on RHEL7.\n> Could you meet this problem on RHEL7? \n\nI didn't test it on RHEL7, but it should be reproducible without this fix on RHEL7, too, when you try to boot a libvirt guest with a single NUMA cell requested.\n\nI hit this bug while booting libvirt guest in the context of OpenStack in a developer environment (DevStack) on Fedora-21, you can see how I tested it here (it's a bit involved procedure):\n\n  https://bugzilla.redhat.com/show_bug.cgi?id=1168672#c8\n\n> Is nested KVM necessary for this bug?\n\nNested KVM is not mandatory (but my test environment involved nested KVM). However, you do need a physical machine with more than a single NUMA cell. You can find that out by running: \n\n  $ virsh nodeinfo\n\n\nYou can probably try to reproduce this issue by trying to boot a libvirt guest with a single NUMA node. You can see the QEMU CLI from the parent bug, here:\n\n  https://bugzilla.redhat.com/show_bug.cgi?id=1168672#c9\n\nSpecifically, notice this from the QEMU CLI:\n\n[. . .]\n-object memory-backend-ram,size=1024M,id=ram-node0,host-nodes=0,policy=bind -numa node,nodeid=0,cpus=0-3,memdev=ram-node0\n[. . .]"
							},
							{
								"isprivate": "0",
								"commentid": "7754612",
								"comment_count": "8",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-11 10:06:53 +0000",
								"thetext": "Hi Martin and Kashyap,\n\nI tested it on a machine with 2 nodes, and configured 1 guest node.\n\n...\n  <vcpu placement='auto'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='0-3'/>\n    <vcpupin vcpu='1' cpuset='0-3'/>\n    <vcpupin vcpu='2' cpuset='0-3'/>\n    <vcpupin vcpu='3' cpuset='0-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n    <memnode cellid='0' mode='strict' nodeset='0'/>\n  </numatune>\n...\n  <cpu mode='host-passthrough'>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n...\n\n\nBut I got \n\"\nerror: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2db.scope/vcpu0/cpuset.cpus': Permission denied\n\"\n\nIt is not 'cpuset.mems: Device or resource busy'. \n\nDoes it same with this bug?"
							},
							{
								"isprivate": "0",
								"commentid": "7754739",
								"comment_count": "9",
								"who": {
									"text": "mkletzan",
									"name": "Martin Kletzander"
								},
								"bug_when": "2014-12-11 10:46:42 +0000",
								"thetext": "No, permission denied is something completely different.  I don't even know how this is possible :)"
							},
							{
								"isprivate": "0",
								"commentid": "7763751",
								"comment_count": "10",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-15 08:32:33 +0000",
								"thetext": "(In reply to Martin Kletzander from comment #9)\n> No, permission denied is something completely different.  I don't even know\n> how this is possible :)\n\nOK, I already filed a bug 1174125 for \"cpuset.cpus: Permission denied\" problem."
							},
							{
								"isprivate": "0",
								"commentid": "7773089",
								"comment_count": "11",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-17 09:33:49 +0000",
								"thetext": "This bug is cloned from fedora, so it couldn't be reproduced on RHEL.\n\nBut I have one method to reproduce it, using package libvirt-1.2.8-10.el7.\n\nRebuild libvirt-1.2.8-10.el7 with 411cea6 and without c6e9024\n\n\ncommit 411cea638f6ec8503b7142a31e58b1cd85dbeaba\nAuthor: Zhou yimin <zhouyimin@huawei.com>\nDate:   Thu Oct 16 22:18:48 2014 +0800\n\n    qemu: move setting emulatorpin ahead of monitor showing up\n\ncommit c6e90248676126c209b3b6017ad27cf6c6a0ab8f\nAuthor: Wang Rui <moon.wangrui@huawei.com>\nDate:   Mon Nov 10 21:53:19 2014 +0800\n\n    qemu: fix domain startup failing with 'strict' mode in numatune\n\n\nAfter that, I could reproduce this problem:\n# virsh edit b\n...\n  <vcpu placement='auto'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='1-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n  </numatune>\n...\n  <cpu mode='host-passthrough'>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n...\n\n# virsh start b\nerror: Failed to start domain b\nerror: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2db.scope/cpuset.mems': Device or resource busy\n\n\nAs commit c6e9024 said:\n\"\nIt's broken by Commit 411cea638f6ec8503b7142a31e58b1cd85dbeaba\nwhich moved qemuSetupCgroupForEmulator() before setting cpuset.mems\nin qemuSetupCgroupPostInit.\n\nDirectory '$cgroup_path/emulator/' is created in qemuSetupCgroupForEmulator.\nBut '$cgroup_path/emulator/cpuset.mems' it not set and has a default value\n(all nodes, such as 0-1). Then we setup '$cgroup_path/cpuset.mems' to the\nnodemask (in this case it's '0') in qemuSetupCgroupPostInit. It must fail.\n\""
							},
							{
								"isprivate": "0",
								"commentid": "7773142",
								"comment_count": "12",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-17 09:42:44 +0000",
								"thetext": "The problem \"cpuset.cpus: Permission denied\" is due to the inconsistent between numad and vcpupin user specified. I will post log in bug 1174125."
							},
							{
								"isprivate": "0",
								"commentid": "7773242",
								"comment_count": "13",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-17 10:06:08 +0000",
								"thetext": "So this commit from upstream should be add:\n\ncommit 411cea638f6ec8503b7142a31e58b1cd85dbeaba\nAuthor: Zhou yimin <zhouyimin@huawei.com>\nDate:   Thu Oct 16 22:18:48 2014 +0800\n\n    qemu: move setting emulatorpin ahead of monitor showing up"
							},
							{
								"isprivate": "0",
								"commentid": "7773267",
								"comment_count": "14",
								"who": {
									"text": "jdenemar",
									"name": "Jiri Denemark"
								},
								"bug_when": "2014-12-17 10:09:36 +0000",
								"thetext": "Yeah, it will be added for bug 1170484."
							},
							{
								"isprivate": "0",
								"commentid": "7776273",
								"comment_count": "15",
								"who": {
									"text": "jmiao",
									"name": "Jincheng Miao"
								},
								"bug_when": "2014-12-18 03:18:22 +0000",
								"thetext": "Since this upstream commit 411cea6 is backported in latest libvirt-1.2.8-11.el7.x86_64, I will use it to test this bug.\n\n# rpm -q libvirt\nlibvirt-1.2.8-11.el7.x86_64\n\n1. using the same guest configuration:\n# virsh edit b\n...\n  <vcpu placement='static'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='1-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n  </numatune>\n...\n  <cpu mode='host-passthrough'>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n...\n\n2. start guest\n# virsh start b\nDomain b started\n\nUsing vcpu placement='auto' also triggers \"cpuset.cpus: Permission denied\", but bug 1174125 will cover it.\n\nSo I will change the status to VERIFIED."
							},
							{
								"isprivate": "0",
								"commentid": "8009334",
								"comment_count": "17",
								"who": {
									"text": "errata-xmlrpc",
									"name": "errata-xmlrpc"
								},
								"bug_when": "2015-03-05 07:47:47 +0000",
								"thetext": "Since the problem described in this bug report should be\nresolved in a recent advisory, it has been closed with a\nresolution of ERRATA.\n\nFor information on the advisory, and where to find the updated\nfiles, follow the link below.\n\nIf the solution does not work for you, open a new bug report.\n\nhttps://rhn.redhat.com/errata/RHSA-2015-0323.html"
							}
						]
					},
					{
						"bug_id": "1168944",
						"creation_ts": "2014-11-28 13:46:27 +0000",
						"short_desc": "\"libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\"",
						"delta_ts": "2014-11-28 14:13:24 +0000",
						"bug_status": "CLOSED",
						"resolution": "DUPLICATE",
						"keywords": "Upstream",
						"priority": "unspecified",
						"bug_severity": "unspecified",
						"depends_on": [
							"1168672"
						],
						"blocked": [
							{
								"bug_id": "1168866",
								"creation_ts": "2014-11-28 09:41:19 +0000",
								"short_desc": "\"libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\"",
								"delta_ts": "2015-03-05 07:47:47 +0000",
								"bug_status": "CLOSED",
								"resolution": "ERRATA",
								"keywords": "Upstream",
								"priority": "unspecified",
								"bug_severity": "medium",
								"depends_on": [
									"1168672",
									"1168944"
								],
								"external_bugs": {
									"text": "RHSA-2015:0323",
									"name": "Red Hat Product Errata"
								},
								"long_desc": [
									{
										"isprivate": "0",
										"commentid": "7716124",
										"comment_count": "0",
										"who": {
											"text": "jsuchane",
											"name": "Jaroslav Suchanek"
										},
										"bug_when": "2014-11-28 09:41:19 +0000",
										"thetext": "+++ This bug was initially created as a clone of Bug #1168672 +++\n\nDescription of problem\n----------------------\n\nThis occurs when you boot a Nova instance with NUMA topology.\n\n[. . .]\nlibvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .'\n\nVersion\n-------\n\nVersions of libvirt, QEMU, systemd in the OpenStack setup (running in a\nDevStack VM):\n\n  $ uname -r; rpm -q libvirt-daemon-kvm qemu-system-x86 systemd\n  3.18.0-0.rc6.git0.1.fc22.x86_64\n  libvirt-daemon-kvm-1.2.10-3.fc22.x86_64\n  qemu-system-x86-2.2.0-0.1.rc1.fc22.x86_64\n  systemd-216-11.fc21.x86_64\n\n\nHow reproducible: Atleast twice.\n\n\nSteps to reproduce\n------------------\n\nThis occurred in when booting a Nova instance in a DevStack (OpenStack\ndeveloper setup) environment. The DevStack machine is a KVM guest\nhypervisor, and the Nova guest is a nested guest running on this.\n\nIt's a fairly involved test environment, details here:\n\nhttp://docs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\ndocs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\n\n\nActual results\n--------------\n\n[. . .]\n2014-11-26 20:17:28.722 ERROR nova.compute.manager [-] [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Instance failed to spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Traceback (most recent call last):\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2247, in _build_resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     yield resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2117, in _build_and_run_instance\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     instance_type=instance_type)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/li\nbvirt/driver.py\", line 2640, in spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     block_device_info, disk_info=disk_info)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4500, in _create_domain_and_network\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     power_on=power_on)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4433, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     LOG.error(err)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/oslo/utils/excutils.py\", line 82, in __exit__\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(self.type_, self.value, self.tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4423, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     domain.createWithFlags(launch_flags)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = execute(f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(c, e, tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = meth(*args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 1033, in createWithFlags\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .]\n\n\nExpected results\n----------------\n\nNova instance (libvirt nested guest) should boot successfully.\n\n\nAdditional info\n---------------\n\n[1] Inventory of available NUMA nodes on the physical host:\n\n$ numactl --hardware\navailable: 4 nodes (0-3)\nnode 0 cpus: 0 4 8 12 16 20 24 28 32 36 40 44\nnode 0 size: 257954 MB\nnode 0 free: 248486 MB\nnode 1 cpus: 1 5 9 13 17 21 25 29 33 37 41 45\nnode 1 size: 258045 MB\nnode 1 free: 256470 MB\nnode 2 cpus: 2 6 10 14 18 22 26 30 34 38 42 46\nnode 2 size: 258045 MB\nnode 2 free: 256507 MB\nnode 3 cpus: 3 7 11 15 19 23 27 31 35 39 43 47\nnode 3 size: 258040 MB\nnode 3 free: 256457 MB\nnode distances:\nnode   0   1   2   3 \n  0:  10  20  20  20 \n  1:  20  10  20  20 \n  2:  20  20  10  20 \n  3:  20  20  20  10 \n\n[2] From sytemd `journactl`:\n\n$ sudo journalctl -u libvirtd -l -p err\n[. . .]\nNov 26 09:19:49 devstack libvirtd[32697]: driver in virRegisterStorageDriver must not be NULL\nNov 26 09:19:49 devstack libvirtd[32697]: Failed module registration vboxStorageRegister\nNov 26 10:33:51 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 11:12:36 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 20:17:28 devstack libvirtd[32697]: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\nNov 26 20:17:28 devstack libvirtd[32697]: error from service: TerminateMachine: No machine 'qemu-instance-00000002' known\n[. . .]\n\n\n[3] From an existing Nova instance (that was booted _without_ NUMA)\n\n    $ find /sys/fs/cgroup/cpuset/machine.slice/machine-qemu*/ -name cpuset.mems \n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/vcpu0/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/emulator/cpuset.mems\n    \n    $ cd /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\\\x2dinstance\\\\x2d00000001.scope/\n    $ cat cpuset.mems vcpu0/cpuset.mems emulator/cpuset.mems \n    0-2\n    0-2\n    0-2\n\n\n[4] libvirt developer Martin Kletzander confirmed on IRC (#virt, OFTC) that\nthis is a bug.\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:16:02 EST ---\n\nContextual snippet related to cgroups from the attached libvirtd debug log:\n\n[. . .]\n2014-11-27 14:18:20.835+0000: 25475: debug : virCgroupSetValueStr:718 : Set value '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems' to '0'\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 25\n2014-11-27 14:18:20.836+0000: 25475: error : virCgroupSetValueStr:728 : Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems': Device or resource busy\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 24\n[. . .]\n2014-11-27 14:18:21.041+0000: 25475: debug : virDBusMessageIterEncode:640 : Popping iter=0x7fd43ef944d0\n2014-11-27 14:18:21.042+0000: 25475: error : virDBusCall:1537 : error from service: TerminateMachine: No machine 'qemu-instance-00000003' known\n2014-11-27 14:18:21.042+0000: 25475: debug : qemuRemoveCgroup:1222 : Failed to terminate cgroup for instance-00000003\n2014-11-27 14:18:21.042+0000: 25475: debug : virObjectUnref:259 : OBJECT_UNREF: obj=0x7fd4300e6890\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3331 : Removing cgroup /machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemoveRecursively:3302 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope//emulator\n[. . .]\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:28:09 EST ---\n\nDevStack machine's capabilities where the Nova Compute service is running and a libvirt instance (a nested guest) failed to started)\n\n---------------------\nDevStack>$ virsh capabilities\n<capabilities>\n\n  <host>\n    <uuid>7dae2ee3-8950-9a41-9e24-a463a8563bbd</uuid>\n    <cpu>\n      <arch>x86_64</arch>\n      <model>Nehalem</model>\n      <vendor>Intel</vendor>\n      <topology sockets='1' cores='8' threads='1'/>\n      <feature name='rdtscp'/>\n      <feature name='hypervisor'/>\n      <feature name='x2apic'/>\n      <feature name='vmx'/>\n      <feature name='ss'/>\n      <feature name='vme'/>\n      <pages unit='KiB' size='4'/>\n      <pages unit='KiB' size='2048'/>\n    </cpu>\n    <power_management>\n      <suspend_mem/>\n      <suspend_disk/>\n      <suspend_hybrid/>\n    </power_management>\n    <migration_features>\n      <live/>\n      <uri_transports>\n        <uri_transport>tcp</uri_transport>\n        <uri_transport>rdma</uri_transport>\n      </uri_transports>\n    </migration_features>\n    <topology>\n      <cells num='3'>\n        <cell id='0'>\n          <memory unit='KiB'>3949740</memory>\n          <pages unit='KiB' size='4'>987435</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='10'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='4'>\n            <cpu id='0' socket_id='0' core_id='0' siblings='0'/>\n            <cpu id='1' socket_id='1' core_id='0' siblings='1'/>\n            <cpu id='2' socket_id='2' core_id='0' siblings='2'/>\n            <cpu id='3' socket_id='3' core_id='0' siblings='3'/>\n          </cpus>\n        </cell>\n        <cell id='1'>\n          <memory unit='KiB'>2016864</memory>\n          <pages unit='KiB' size='4'>504216</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='10'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='4' socket_id='4' core_id='0' siblings='4'/>\n            <cpu id='5' socket_id='5' core_id='0' siblings='5'/>\n          </cpus>\n        </cell>\n        <cell id='2'>\n          <memory unit='KiB'>2014304</memory>\n          <pages unit='KiB' size='4'>503576</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='10'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='6' socket_id='6' core_id='0' siblings='6'/>\n            <cpu id='7' socket_id='7' core_id='0' siblings='7'/>\n          </cpus>\n        </cell>\n      </cells>\n    </topology>\n    <secmodel>\n      <model>selinux</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>system_u:system_r:svirt_t:s0</baselabel>\n      <baselabel type='qemu'>system_u:system_r:svirt_tcg_t:s0</baselabel>\n    </secmodel>\n    <secmodel>\n      <model>dac</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>+107:+107</baselabel>\n      <baselabel type='qemu'>+107:+107</baselabel>\n    </secmodel>\n  </host>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='i686'>\n      <wordsize>32</wordsize>\n      <emulator>/usr/bin/qemu-system-i386</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n      <pae/>\n      <nonpae/>\n    </features>\n  </guest>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='x86_64'>\n      <wordsize>64</wordsize>\n      <emulator>/usr/bin/qemu-system-x86_64</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n    </features>\n  </guest>\n\n</capabilities>\n---------------------\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:29:07 EST ---\n\n\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:33:39 EST ---\n\nContextual snippet from the attachment:\n\n[. . .]\n  <memory>1048576</memory>\n  <numatune>\n    <memory mode=\"strict\" nodeset=\"0\"/>\n    <memnode cellid=\"0\" mode=\"strict\" nodeset=\"0\"/>\n  </numatune>\n  <vcpu>4</vcpu>\n  <metadata>\n    <nova:instance xmlns:nova=\"http://openstack.org/xmlns/libvirt/nova/1.0\">\n      <nova:package version=\"2015.1\"/>\n      <nova:name>cirrvm3</nova:name>\n      <nova:creationTime>2014-11-27 14:18:18</nova:creationTime>\n      <nova:flavor name=\"m1.numa\">\n        <nova:memory>1024</nova:memory>\n        <nova:disk>1</nova:disk>\n        <nova:swap>0</nova:swap>\n        <nova:ephemeral>0</nova:ephemeral>\n        <nova:vcpus>4</nova:vcpus>\n      </nova:flavor>\n      <nova:owner>\n        <nova:user uuid=\"e2ab0e48d003456da53e892366651175\">admin</nova:user>\n        <nova:project uuid=\"a9a2cd5511214089a290ccfcac47502c\">admin</nova:project>\n      </nova:owner>\n      <nova:root type=\"image\" uuid=\"178c675a-d5fb-459f-a850-f7ffa6e2c9d2\"/>\n    </nova:instance>\n  </metadata>\n[. . .]\n  <cputune>\n    <emulatorpin cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"0\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"1\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"2\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"3\" cpuset=\"0-3\"/>\n  </cputune>\n[. . .]\n\n--- Additional comment from Nikola Dipanov on 2014-11-27 12:10:46 EST ---\n\nIt might also be relevant that in this case, the domain XML will as well have a <numa> element specified."
									},
									{
										"isprivate": "0",
										"commentid": "7716838",
										"comment_count": "1",
										"who": {
											"text": "mkletzan",
											"name": "Martin Kletzander"
										},
										"bug_when": "2014-11-28 13:32:42 +0000",
										"thetext": "Fixed upstream with v1.2.10-75-gc6e9024:\n\ncommit c6e90248676126c209b3b6017ad27cf6c6a0ab8f\nAuthor: Wang Rui <moon.wangrui@huawei.com>\nDate:   Mon Nov 10 21:53:19 2014 +0800\n\n    qemu: fix domain startup failing with 'strict' mode in numatune"
									},
									{
										"isprivate": "0",
										"commentid": "7716955",
										"comment_count": "3",
										"who": {
											"text": "kchamart",
											"name": "Kashyap Chamarthy"
										},
										"bug_when": "2014-11-28 14:13:24 +0000",
										"thetext": "*** Bug 1168944 has been marked as a duplicate of this bug. ***"
									},
									{
										"isprivate": "0",
										"commentid": "7749668",
										"comment_count": "5",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-10 08:01:24 +0000",
										"thetext": "*** Bug 1118517 has been marked as a duplicate of this bug. ***"
									},
									{
										"isprivate": "0",
										"commentid": "7754214",
										"comment_count": "6",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-11 08:16:35 +0000",
										"thetext": "Hi Kashyap，\n\nI am libvirt qe, and trying to reproduce this bug on RHEL7.\nCould you meet this problem on RHEL7? Is nested KVM necessary for this bug?"
									},
									{
										"isprivate": "0",
										"commentid": "7754410",
										"comment_count": "7",
										"who": {
											"text": "kchamart",
											"name": "Kashyap Chamarthy"
										},
										"bug_when": "2014-12-11 09:14:45 +0000",
										"thetext": "(In reply to Jincheng Miao from comment #6)\n> Hi Kashyap，\n\nHi Jincheng,\n\n> \n> I am libvirt qe, and trying to reproduce this bug on RHEL7.\n> Could you meet this problem on RHEL7? \n\nI didn't test it on RHEL7, but it should be reproducible without this fix on RHEL7, too, when you try to boot a libvirt guest with a single NUMA cell requested.\n\nI hit this bug while booting libvirt guest in the context of OpenStack in a developer environment (DevStack) on Fedora-21, you can see how I tested it here (it's a bit involved procedure):\n\n  https://bugzilla.redhat.com/show_bug.cgi?id=1168672#c8\n\n> Is nested KVM necessary for this bug?\n\nNested KVM is not mandatory (but my test environment involved nested KVM). However, you do need a physical machine with more than a single NUMA cell. You can find that out by running: \n\n  $ virsh nodeinfo\n\n\nYou can probably try to reproduce this issue by trying to boot a libvirt guest with a single NUMA node. You can see the QEMU CLI from the parent bug, here:\n\n  https://bugzilla.redhat.com/show_bug.cgi?id=1168672#c9\n\nSpecifically, notice this from the QEMU CLI:\n\n[. . .]\n-object memory-backend-ram,size=1024M,id=ram-node0,host-nodes=0,policy=bind -numa node,nodeid=0,cpus=0-3,memdev=ram-node0\n[. . .]"
									},
									{
										"isprivate": "0",
										"commentid": "7754612",
										"comment_count": "8",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-11 10:06:53 +0000",
										"thetext": "Hi Martin and Kashyap,\n\nI tested it on a machine with 2 nodes, and configured 1 guest node.\n\n...\n  <vcpu placement='auto'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='0-3'/>\n    <vcpupin vcpu='1' cpuset='0-3'/>\n    <vcpupin vcpu='2' cpuset='0-3'/>\n    <vcpupin vcpu='3' cpuset='0-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n    <memnode cellid='0' mode='strict' nodeset='0'/>\n  </numatune>\n...\n  <cpu mode='host-passthrough'>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n...\n\n\nBut I got \n\"\nerror: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2db.scope/vcpu0/cpuset.cpus': Permission denied\n\"\n\nIt is not 'cpuset.mems: Device or resource busy'. \n\nDoes it same with this bug?"
									},
									{
										"isprivate": "0",
										"commentid": "7754739",
										"comment_count": "9",
										"who": {
											"text": "mkletzan",
											"name": "Martin Kletzander"
										},
										"bug_when": "2014-12-11 10:46:42 +0000",
										"thetext": "No, permission denied is something completely different.  I don't even know how this is possible :)"
									},
									{
										"isprivate": "0",
										"commentid": "7763751",
										"comment_count": "10",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-15 08:32:33 +0000",
										"thetext": "(In reply to Martin Kletzander from comment #9)\n> No, permission denied is something completely different.  I don't even know\n> how this is possible :)\n\nOK, I already filed a bug 1174125 for \"cpuset.cpus: Permission denied\" problem."
									},
									{
										"isprivate": "0",
										"commentid": "7773089",
										"comment_count": "11",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-17 09:33:49 +0000",
										"thetext": "This bug is cloned from fedora, so it couldn't be reproduced on RHEL.\n\nBut I have one method to reproduce it, using package libvirt-1.2.8-10.el7.\n\nRebuild libvirt-1.2.8-10.el7 with 411cea6 and without c6e9024\n\n\ncommit 411cea638f6ec8503b7142a31e58b1cd85dbeaba\nAuthor: Zhou yimin <zhouyimin@huawei.com>\nDate:   Thu Oct 16 22:18:48 2014 +0800\n\n    qemu: move setting emulatorpin ahead of monitor showing up\n\ncommit c6e90248676126c209b3b6017ad27cf6c6a0ab8f\nAuthor: Wang Rui <moon.wangrui@huawei.com>\nDate:   Mon Nov 10 21:53:19 2014 +0800\n\n    qemu: fix domain startup failing with 'strict' mode in numatune\n\n\nAfter that, I could reproduce this problem:\n# virsh edit b\n...\n  <vcpu placement='auto'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='1-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n  </numatune>\n...\n  <cpu mode='host-passthrough'>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n...\n\n# virsh start b\nerror: Failed to start domain b\nerror: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2db.scope/cpuset.mems': Device or resource busy\n\n\nAs commit c6e9024 said:\n\"\nIt's broken by Commit 411cea638f6ec8503b7142a31e58b1cd85dbeaba\nwhich moved qemuSetupCgroupForEmulator() before setting cpuset.mems\nin qemuSetupCgroupPostInit.\n\nDirectory '$cgroup_path/emulator/' is created in qemuSetupCgroupForEmulator.\nBut '$cgroup_path/emulator/cpuset.mems' it not set and has a default value\n(all nodes, such as 0-1). Then we setup '$cgroup_path/cpuset.mems' to the\nnodemask (in this case it's '0') in qemuSetupCgroupPostInit. It must fail.\n\""
									},
									{
										"isprivate": "0",
										"commentid": "7773142",
										"comment_count": "12",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-17 09:42:44 +0000",
										"thetext": "The problem \"cpuset.cpus: Permission denied\" is due to the inconsistent between numad and vcpupin user specified. I will post log in bug 1174125."
									},
									{
										"isprivate": "0",
										"commentid": "7773242",
										"comment_count": "13",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-17 10:06:08 +0000",
										"thetext": "So this commit from upstream should be add:\n\ncommit 411cea638f6ec8503b7142a31e58b1cd85dbeaba\nAuthor: Zhou yimin <zhouyimin@huawei.com>\nDate:   Thu Oct 16 22:18:48 2014 +0800\n\n    qemu: move setting emulatorpin ahead of monitor showing up"
									},
									{
										"isprivate": "0",
										"commentid": "7773267",
										"comment_count": "14",
										"who": {
											"text": "jdenemar",
											"name": "Jiri Denemark"
										},
										"bug_when": "2014-12-17 10:09:36 +0000",
										"thetext": "Yeah, it will be added for bug 1170484."
									},
									{
										"isprivate": "0",
										"commentid": "7776273",
										"comment_count": "15",
										"who": {
											"text": "jmiao",
											"name": "Jincheng Miao"
										},
										"bug_when": "2014-12-18 03:18:22 +0000",
										"thetext": "Since this upstream commit 411cea6 is backported in latest libvirt-1.2.8-11.el7.x86_64, I will use it to test this bug.\n\n# rpm -q libvirt\nlibvirt-1.2.8-11.el7.x86_64\n\n1. using the same guest configuration:\n# virsh edit b\n...\n  <vcpu placement='static'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='1-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n  </numatune>\n...\n  <cpu mode='host-passthrough'>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n...\n\n2. start guest\n# virsh start b\nDomain b started\n\nUsing vcpu placement='auto' also triggers \"cpuset.cpus: Permission denied\", but bug 1174125 will cover it.\n\nSo I will change the status to VERIFIED."
									},
									{
										"isprivate": "0",
										"commentid": "8009334",
										"comment_count": "17",
										"who": {
											"text": "errata-xmlrpc",
											"name": "errata-xmlrpc"
										},
										"bug_when": "2015-03-05 07:47:47 +0000",
										"thetext": "Since the problem described in this bug report should be\nresolved in a recent advisory, it has been closed with a\nresolution of ERRATA.\n\nFor information on the advisory, and where to find the updated\nfiles, follow the link below.\n\nIf the solution does not work for you, open a new bug report.\n\nhttps://rhn.redhat.com/errata/RHSA-2015-0323.html"
									}
								]
							}
						],
						"long_desc": [
							{
								"isprivate": "0",
								"commentid": "7716867",
								"comment_count": "0",
								"who": {
									"text": "kchamart",
									"name": "Kashyap Chamarthy"
								},
								"bug_when": "2014-11-28 13:46:27 +0000",
								"thetext": "[This bug is fixed in libvirt upstream git, and will be available in 1.2.11. libvirt commit that fixes it: c6e90248676126c209b3b6017ad27cf6c6a0ab8f ]\n\n+++ This bug was initially created as a clone of Bug #1168672 +++\n\nDescription of problem\n----------------------\n\nThis occurs when you boot a Nova instance with NUMA topology.\n\n[. . .]\nlibvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .'\n\nVersion\n-------\n\nVersions of libvirt, QEMU, systemd in the OpenStack setup (running in a\nDevStack VM):\n\n  $ uname -r; rpm -q libvirt-daemon-kvm qemu-system-x86 systemd\n  3.18.0-0.rc6.git0.1.fc22.x86_64\n  libvirt-daemon-kvm-1.2.10-3.fc22.x86_64\n  qemu-system-x86-2.2.0-0.1.rc1.fc22.x86_64\n  systemd-216-11.fc21.x86_64\n\n\nHow reproducible: Atleast twice.\n\n\nSteps to reproduce\n------------------\n\nThis occurred in when booting a Nova instance in a DevStack (OpenStack\ndeveloper setup) environment. The DevStack machine is a KVM guest\nhypervisor, and the Nova guest is a nested guest running on this.\n\nIt's a fairly involved test environment, details here:\n\nhttp://docs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\ndocs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\n\n\nActual results\n--------------\n\n[. . .]\n2014-11-26 20:17:28.722 ERROR nova.compute.manager [-] [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Instance failed to spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Traceback (most recent call last):\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2247, in _build_resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     yield resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2117, in _build_and_run_instance\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     instance_type=instance_type)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/li\nbvirt/driver.py\", line 2640, in spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     block_device_info, disk_info=disk_info)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4500, in _create_domain_and_network\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     power_on=power_on)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4433, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     LOG.error(err)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/oslo/utils/excutils.py\", line 82, in __exit__\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(self.type_, self.value, self.tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4423, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     domain.createWithFlags(launch_flags)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = execute(f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(c, e, tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = meth(*args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 1033, in createWithFlags\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .]\n\n\nExpected results\n----------------\n\nNova instance (libvirt nested guest) should boot successfully.\n\n\nAdditional info\n---------------\n\n[1] Inventory of available NUMA nodes on the physical host:\n\n$ numactl --hardware\navailable: 4 nodes (0-3)\nnode 0 cpus: 0 4 8 12 16 20 24 28 32 36 40 44\nnode 0 size: 257954 MB\nnode 0 free: 248486 MB\nnode 1 cpus: 1 5 9 13 17 21 25 29 33 37 41 45\nnode 1 size: 258045 MB\nnode 1 free: 256470 MB\nnode 2 cpus: 2 6 10 14 18 22 26 30 34 38 42 46\nnode 2 size: 258045 MB\nnode 2 free: 256507 MB\nnode 3 cpus: 3 7 11 15 19 23 27 31 35 39 43 47\nnode 3 size: 258040 MB\nnode 3 free: 256457 MB\nnode distances:\nnode   0   1   2   3 \n  0:  10  20  20  20 \n  1:  20  10  20  20 \n  2:  20  20  10  20 \n  3:  20  20  20  10 \n\n[2] From sytemd `journactl`:\n\n$ sudo journalctl -u libvirtd -l -p err\n[. . .]\nNov 26 09:19:49 devstack libvirtd[32697]: driver in virRegisterStorageDriver must not be NULL\nNov 26 09:19:49 devstack libvirtd[32697]: Failed module registration vboxStorageRegister\nNov 26 10:33:51 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 11:12:36 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 20:17:28 devstack libvirtd[32697]: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\nNov 26 20:17:28 devstack libvirtd[32697]: error from service: TerminateMachine: No machine 'qemu-instance-00000002' known\n[. . .]\n\n\n[3] From an existing Nova instance (that was booted _without_ NUMA)\n\n    $ find /sys/fs/cgroup/cpuset/machine.slice/machine-qemu*/ -name cpuset.mems \n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/vcpu0/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/emulator/cpuset.mems\n    \n    $ cd /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\\\x2dinstance\\\\x2d00000001.scope/\n    $ cat cpuset.mems vcpu0/cpuset.mems emulator/cpuset.mems \n    0-2\n    0-2\n    0-2\n\n\n[4] libvirt developer Martin Kletzander confirmed on IRC (#virt, OFTC) that\nthis is a bug.\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:16:02 EST ---\n\nContextual snippet related to cgroups from the attached libvirtd debug log:\n\n[. . .]\n2014-11-27 14:18:20.835+0000: 25475: debug : virCgroupSetValueStr:718 : Set value '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems' to '0'\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 25\n2014-11-27 14:18:20.836+0000: 25475: error : virCgroupSetValueStr:728 : Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems': Device or resource busy\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 24\n[. . .]\n2014-11-27 14:18:21.041+0000: 25475: debug : virDBusMessageIterEncode:640 : Popping iter=0x7fd43ef944d0\n2014-11-27 14:18:21.042+0000: 25475: error : virDBusCall:1537 : error from service: TerminateMachine: No machine 'qemu-instance-00000003' known\n2014-11-27 14:18:21.042+0000: 25475: debug : qemuRemoveCgroup:1222 : Failed to terminate cgroup for instance-00000003\n2014-11-27 14:18:21.042+0000: 25475: debug : virObjectUnref:259 : OBJECT_UNREF: obj=0x7fd4300e6890\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3331 : Removing cgroup /machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemoveRecursively:3302 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope//emulator\n[. . .]\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:28:09 EST ---\n\nDevStack machine's capabilities where the Nova Compute service is running and a libvirt instance (a nested guest) failed to started)\n\n---------------------\nDevStack>$ virsh capabilities\n<capabilities>\n\n  <host>\n    <uuid>7dae2ee3-8950-9a41-9e24-a463a8563bbd</uuid>\n    <cpu>\n      <arch>x86_64</arch>\n      <model>Nehalem</model>\n      <vendor>Intel</vendor>\n      <topology sockets='1' cores='8' threads='1'/>\n      <feature name='rdtscp'/>\n      <feature name='hypervisor'/>\n      <feature name='x2apic'/>\n      <feature name='vmx'/>\n      <feature name='ss'/>\n      <feature name='vme'/>\n      <pages unit='KiB' size='4'/>\n      <pages unit='KiB' size='2048'/>\n    </cpu>\n    <power_management>\n      <suspend_mem/>\n      <suspend_disk/>\n      <suspend_hybrid/>\n    </power_management>\n    <migration_features>\n      <live/>\n      <uri_transports>\n        <uri_transport>tcp</uri_transport>\n        <uri_transport>rdma</uri_transport>\n      </uri_transports>\n    </migration_features>\n    <topology>\n      <cells num='3'>\n        <cell id='0'>\n          <memory unit='KiB'>3949740</memory>\n          <pages unit='KiB' size='4'>987435</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='10'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='4'>\n            <cpu id='0' socket_id='0' core_id='0' siblings='0'/>\n            <cpu id='1' socket_id='1' core_id='0' siblings='1'/>\n            <cpu id='2' socket_id='2' core_id='0' siblings='2'/>\n            <cpu id='3' socket_id='3' core_id='0' siblings='3'/>\n          </cpus>\n        </cell>\n        <cell id='1'>\n          <memory unit='KiB'>2016864</memory>\n          <pages unit='KiB' size='4'>504216</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='10'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='4' socket_id='4' core_id='0' siblings='4'/>\n            <cpu id='5' socket_id='5' core_id='0' siblings='5'/>\n          </cpus>\n        </cell>\n        <cell id='2'>\n          <memory unit='KiB'>2014304</memory>\n          <pages unit='KiB' size='4'>503576</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='10'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='6' socket_id='6' core_id='0' siblings='6'/>\n            <cpu id='7' socket_id='7' core_id='0' siblings='7'/>\n          </cpus>\n        </cell>\n      </cells>\n    </topology>\n    <secmodel>\n      <model>selinux</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>system_u:system_r:svirt_t:s0</baselabel>\n      <baselabel type='qemu'>system_u:system_r:svirt_tcg_t:s0</baselabel>\n    </secmodel>\n    <secmodel>\n      <model>dac</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>+107:+107</baselabel>\n      <baselabel type='qemu'>+107:+107</baselabel>\n    </secmodel>\n  </host>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='i686'>\n      <wordsize>32</wordsize>\n      <emulator>/usr/bin/qemu-system-i386</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n      <pae/>\n      <nonpae/>\n    </features>\n  </guest>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='x86_64'>\n      <wordsize>64</wordsize>\n      <emulator>/usr/bin/qemu-system-x86_64</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n    </features>\n  </guest>\n\n</capabilities>\n---------------------\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:29:07 EST ---\n\n\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-27 10:33:39 EST ---\n\nContextual snippet from the attachment:\n\n[. . .]\n  <memory>1048576</memory>\n  <numatune>\n    <memory mode=\"strict\" nodeset=\"0\"/>\n    <memnode cellid=\"0\" mode=\"strict\" nodeset=\"0\"/>\n  </numatune>\n  <vcpu>4</vcpu>\n  <metadata>\n    <nova:instance xmlns:nova=\"http://openstack.org/xmlns/libvirt/nova/1.0\">\n      <nova:package version=\"2015.1\"/>\n      <nova:name>cirrvm3</nova:name>\n      <nova:creationTime>2014-11-27 14:18:18</nova:creationTime>\n      <nova:flavor name=\"m1.numa\">\n        <nova:memory>1024</nova:memory>\n        <nova:disk>1</nova:disk>\n        <nova:swap>0</nova:swap>\n        <nova:ephemeral>0</nova:ephemeral>\n        <nova:vcpus>4</nova:vcpus>\n      </nova:flavor>\n      <nova:owner>\n        <nova:user uuid=\"e2ab0e48d003456da53e892366651175\">admin</nova:user>\n        <nova:project uuid=\"a9a2cd5511214089a290ccfcac47502c\">admin</nova:project>\n      </nova:owner>\n      <nova:root type=\"image\" uuid=\"178c675a-d5fb-459f-a850-f7ffa6e2c9d2\"/>\n    </nova:instance>\n  </metadata>\n[. . .]\n  <cputune>\n    <emulatorpin cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"0\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"1\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"2\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"3\" cpuset=\"0-3\"/>\n  </cputune>\n[. . .]\n\n--- Additional comment from Nikola Dipanov on 2014-11-27 12:10:46 EST ---\n\nIt might also be relevant that in this case, the domain XML will as well have a <numa> element specified.\n\n--- Additional comment from Kashyap Chamarthy on 2014-11-28 07:58:58 EST ---\n\nContextual snippet of Nova guest XML:\n[. . .]\n  <vcpu placement='static'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='0-3'/>\n    <vcpupin vcpu='1' cpuset='0-3'/>\n    <vcpupin vcpu='2' cpuset='0-3'/>\n    <vcpupin vcpu='3' cpuset='0-3'/>\n    <emulatorpin cpuset='0-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n    <memnode cellid='0' mode='strict' nodeset='0'/>\n  </numatune>\n[. . .]\n  <cpu>\n    <topology sockets='4' cores='1' threads='1'/>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n[. . .]\n\n\nI was here in Nova's git when I tested this time:\n\n  nova]$ git describe\n  2014.2-995-g5d2ea10\n\n\nPreviously, I was at:\n\n  nova]$ git describe\n  2014.2-973-g922ca3c\n\n--- Additional comment from Martin Kletzander on 2014-11-28 08:31:01 EST ---\n\nFixed upstream with v1.2.10-75-gc6e9024:\n\ncommit c6e90248676126c209b3b6017ad27cf6c6a0ab8f\nAuthor: Wang Rui <moon.wangrui@huawei.com>\nDate:   Mon Nov 10 21:53:19 2014 +0800\n\n    qemu: fix domain startup failing with 'strict' mode in numatune"
							},
							{
								"isprivate": "0",
								"commentid": "7716954",
								"comment_count": "2",
								"who": {
									"text": "kchamart",
									"name": "Kashyap Chamarthy"
								},
								"bug_when": "2014-11-28 14:13:24 +0000",
								"thetext": "\n\n*** This bug has been marked as a duplicate of bug 1168866 ***"
							}
						]
					}
				],
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7714289",
						"comment_count": "0",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-11-27 14:48:28 +0000",
						"thetext": "Description of problem\n----------------------\n\nThis occurs when you boot a Nova instance with NUMA topology.\n\n[. . .]\nlibvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .'\n\nVersion\n-------\n\nVersions of libvirt, QEMU, systemd in the OpenStack setup (running in a\nDevStack VM):\n\n  $ uname -r; rpm -q libvirt-daemon-kvm qemu-system-x86 systemd\n  3.18.0-0.rc6.git0.1.fc22.x86_64\n  libvirt-daemon-kvm-1.2.10-3.fc22.x86_64\n  qemu-system-x86-2.2.0-0.1.rc1.fc22.x86_64\n  systemd-216-11.fc21.x86_64\n\n\nHow reproducible: Atleast twice.\n\n\nSteps to reproduce\n------------------\n\nThis occurred in when booting a Nova instance in a DevStack (OpenStack\ndeveloper setup) environment. The DevStack machine is a KVM guest\nhypervisor, and the Nova guest is a nested guest running on this.\n\nIt's a fairly involved test environment, details here:\n\nhttp://docs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\ndocs-draft.openstack.org/18/131818/1/check/gate-nova-docs/2ddc418/doc/build/html/devref/testing/libvirt-numa.html#testing-basis-non-numa-usage\n\n\nActual results\n--------------\n\n[. . .]\n2014-11-26 20:17:28.722 ERROR nova.compute.manager [-] [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Instance failed to spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] Traceback (most recent call last):\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2247, in _build_resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     yield resources\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/compute\n/manager.py\", line 2117, in _build_and_run_instance\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     instance_type=instance_type)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/li\nbvirt/driver.py\", line 2640, in spawn\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     block_device_info, disk_info=disk_info)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4500, in _create_domain_and_network\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     power_on=power_on)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4433, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     LOG.error(err)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/oslo/utils/excutils.py\", line 82, in __exit__\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(self.type_, self.value, self.tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/home/kashyapc/src/cloud/nova/nova/virt/libvirt/driver.py\", line 4423, in _create_domain\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     domain.createWithFlags(launch_flags)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = execute(f, *args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     six.reraise(c, e, tb)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     rv = meth(*args, **kwargs)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 1033, in createWithFlags\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2014-11-26 20:17:28.722 TRACE nova.compute.manager [instance: bcb53b78-452c-4695-b39d-754389cd3dd5] libvirtError: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\n[. . .]\n\n\nExpected results\n----------------\n\nNova instance (libvirt nested guest) should boot successfully.\n\n\nAdditional info\n---------------\n\n[1] Inventory of available NUMA nodes on the physical host:\n\n$ numactl --hardware\navailable: 4 nodes (0-3)\nnode 0 cpus: 0 4 8 12 16 20 24 28 32 36 40 44\nnode 0 size: 257954 MB\nnode 0 free: 248486 MB\nnode 1 cpus: 1 5 9 13 17 21 25 29 33 37 41 45\nnode 1 size: 258045 MB\nnode 1 free: 256470 MB\nnode 2 cpus: 2 6 10 14 18 22 26 30 34 38 42 46\nnode 2 size: 258045 MB\nnode 2 free: 256507 MB\nnode 3 cpus: 3 7 11 15 19 23 27 31 35 39 43 47\nnode 3 size: 258040 MB\nnode 3 free: 256457 MB\nnode distances:\nnode   0   1   2   3 \n  0:  10  20  20  20 \n  1:  20  10  20  20 \n  2:  20  20  10  20 \n  3:  20  20  20  10 \n\n[2] From sytemd `journactl`:\n\n$ sudo journalctl -u libvirtd -l -p err\n[. . .]\nNov 26 09:19:49 devstack libvirtd[32697]: driver in virRegisterStorageDriver must not be NULL\nNov 26 09:19:49 devstack libvirtd[32697]: Failed module registration vboxStorageRegister\nNov 26 10:33:51 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 11:12:36 devstack libvirtd[32697]: End of file while reading data: Input/output error\nNov 26 20:17:28 devstack libvirtd[32697]: Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000002.scope/cpuset.mems': Device or resource busy\nNov 26 20:17:28 devstack libvirtd[32697]: error from service: TerminateMachine: No machine 'qemu-instance-00000002' known\n[. . .]\n\n\n[3] From an existing Nova instance (that was booted _without_ NUMA)\n\n    $ find /sys/fs/cgroup/cpuset/machine.slice/machine-qemu*/ -name cpuset.mems \n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/vcpu0/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/cpuset.mems\n    /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000001.scope/emulator/cpuset.mems\n    \n    $ cd /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\\\x2dinstance\\\\x2d00000001.scope/\n    $ cat cpuset.mems vcpu0/cpuset.mems emulator/cpuset.mems \n    0-2\n    0-2\n    0-2\n\n\n[4] libvirt developer Martin Kletzander confirmed on IRC (#virt, OFTC) that\nthis is a bug."
					},
					{
						"isprivate": "0",
						"commentid": "7714505",
						"comment_count": "1",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-11-27 15:16:02 +0000",
						"thetext": "Created attachment 962112\nlibvirt debug log with 'virCgroupSetValueStr' failure when Nova instance is launched\n\nContextual snippet related to cgroups from the attached libvirtd debug log:\n\n[. . .]\n2014-11-27 14:18:20.835+0000: 25475: debug : virCgroupSetValueStr:718 : Set value '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems' to '0'\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 25\n2014-11-27 14:18:20.836+0000: 25475: error : virCgroupSetValueStr:728 : Unable to write to '/sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/cpuset.mems': Device or resource busy\n2014-11-27 14:18:20.836+0000: 25475: debug : virFileClose:99 : Closed fd 24\n[. . .]\n2014-11-27 14:18:21.041+0000: 25475: debug : virDBusMessageIterEncode:640 : Popping iter=0x7fd43ef944d0\n2014-11-27 14:18:21.042+0000: 25475: error : virDBusCall:1537 : error from service: TerminateMachine: No machine 'qemu-instance-00000003' known\n2014-11-27 14:18:21.042+0000: 25475: debug : qemuRemoveCgroup:1222 : Failed to terminate cgroup for instance-00000003\n2014-11-27 14:18:21.042+0000: 25475: debug : virObjectUnref:259 : OBJECT_UNREF: obj=0x7fd4300e6890\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3331 : Removing cgroup /machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpu,cpuacct/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemove:3352 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope/ and all child cgroups\n2014-11-27 14:18:21.042+0000: 25475: debug : virCgroupRemoveRecursively:3302 : Removing cgroup /sys/fs/cgroup/cpuset/machine.slice/machine-qemu\\x2dinstance\\x2d00000003.scope//emulator\n[. . .]"
					},
					{
						"isprivate": "0",
						"commentid": "7714530",
						"comment_count": "2",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-11-27 15:28:09 +0000",
						"thetext": "DevStack machine's capabilities where the Nova Compute service is running and a libvirt instance (a nested guest) failed to started)\n\n---------------------\nDevStack>$ virsh capabilities\n<capabilities>\n\n  <host>\n    <uuid>7dae2ee3-8950-9a41-9e24-a463a8563bbd</uuid>\n    <cpu>\n      <arch>x86_64</arch>\n      <model>Nehalem</model>\n      <vendor>Intel</vendor>\n      <topology sockets='1' cores='8' threads='1'/>\n      <feature name='rdtscp'/>\n      <feature name='hypervisor'/>\n      <feature name='x2apic'/>\n      <feature name='vmx'/>\n      <feature name='ss'/>\n      <feature name='vme'/>\n      <pages unit='KiB' size='4'/>\n      <pages unit='KiB' size='2048'/>\n    </cpu>\n    <power_management>\n      <suspend_mem/>\n      <suspend_disk/>\n      <suspend_hybrid/>\n    </power_management>\n    <migration_features>\n      <live/>\n      <uri_transports>\n        <uri_transport>tcp</uri_transport>\n        <uri_transport>rdma</uri_transport>\n      </uri_transports>\n    </migration_features>\n    <topology>\n      <cells num='3'>\n        <cell id='0'>\n          <memory unit='KiB'>3949740</memory>\n          <pages unit='KiB' size='4'>987435</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='10'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='4'>\n            <cpu id='0' socket_id='0' core_id='0' siblings='0'/>\n            <cpu id='1' socket_id='1' core_id='0' siblings='1'/>\n            <cpu id='2' socket_id='2' core_id='0' siblings='2'/>\n            <cpu id='3' socket_id='3' core_id='0' siblings='3'/>\n          </cpus>\n        </cell>\n        <cell id='1'>\n          <memory unit='KiB'>2016864</memory>\n          <pages unit='KiB' size='4'>504216</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='10'/>\n            <sibling id='2' value='20'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='4' socket_id='4' core_id='0' siblings='4'/>\n            <cpu id='5' socket_id='5' core_id='0' siblings='5'/>\n          </cpus>\n        </cell>\n        <cell id='2'>\n          <memory unit='KiB'>2014304</memory>\n          <pages unit='KiB' size='4'>503576</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='20'/>\n            <sibling id='1' value='20'/>\n            <sibling id='2' value='10'/>\n          </distances>\n          <cpus num='2'>\n            <cpu id='6' socket_id='6' core_id='0' siblings='6'/>\n            <cpu id='7' socket_id='7' core_id='0' siblings='7'/>\n          </cpus>\n        </cell>\n      </cells>\n    </topology>\n    <secmodel>\n      <model>selinux</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>system_u:system_r:svirt_t:s0</baselabel>\n      <baselabel type='qemu'>system_u:system_r:svirt_tcg_t:s0</baselabel>\n    </secmodel>\n    <secmodel>\n      <model>dac</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>+107:+107</baselabel>\n      <baselabel type='qemu'>+107:+107</baselabel>\n    </secmodel>\n  </host>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='i686'>\n      <wordsize>32</wordsize>\n      <emulator>/usr/bin/qemu-system-i386</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n      <pae/>\n      <nonpae/>\n    </features>\n  </guest>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='x86_64'>\n      <wordsize>64</wordsize>\n      <emulator>/usr/bin/qemu-system-x86_64</emulator>\n      <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n      <machine maxCpus='255'>pc-1.3</machine>\n      <machine maxCpus='255'>pc-0.12</machine>\n      <machine maxCpus='255'>pc-q35-1.6</machine>\n      <machine maxCpus='255'>pc-q35-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.6</machine>\n      <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n      <machine maxCpus='255'>pc-i440fx-1.7</machine>\n      <machine maxCpus='1'>xenpv</machine>\n      <machine maxCpus='255'>pc-q35-2.1</machine>\n      <machine maxCpus='255'>pc-0.11</machine>\n      <machine maxCpus='255'>pc-0.10</machine>\n      <machine maxCpus='255'>pc-1.2</machine>\n      <machine maxCpus='1'>isapc</machine>\n      <machine maxCpus='255'>pc-q35-1.4</machine>\n      <machine maxCpus='128'>xenfv</machine>\n      <machine maxCpus='255'>pc-0.15</machine>\n      <machine maxCpus='255'>pc-i440fx-1.5</machine>\n      <machine maxCpus='255'>pc-i440fx-1.4</machine>\n      <machine maxCpus='255'>pc-q35-2.0</machine>\n      <machine maxCpus='255'>pc-0.14</machine>\n      <machine maxCpus='255'>pc-1.1</machine>\n      <machine maxCpus='255'>pc-q35-1.7</machine>\n      <machine maxCpus='255'>pc-i440fx-2.1</machine>\n      <machine maxCpus='255'>pc-1.0</machine>\n      <machine maxCpus='255'>pc-i440fx-2.0</machine>\n      <machine maxCpus='255'>pc-0.13</machine>\n      <domain type='qemu'>\n      </domain>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-kvm</emulator>\n        <machine canonical='pc-i440fx-2.2' maxCpus='255'>pc</machine>\n        <machine maxCpus='255'>pc-1.3</machine>\n        <machine maxCpus='255'>pc-0.12</machine>\n        <machine maxCpus='255'>pc-q35-1.6</machine>\n        <machine maxCpus='255'>pc-q35-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.6</machine>\n        <machine canonical='pc-q35-2.2' maxCpus='255'>q35</machine>\n        <machine maxCpus='255'>pc-i440fx-1.7</machine>\n        <machine maxCpus='1'>xenpv</machine>\n        <machine maxCpus='255'>pc-q35-2.1</machine>\n        <machine maxCpus='255'>pc-0.11</machine>\n        <machine maxCpus='255'>pc-0.10</machine>\n        <machine maxCpus='255'>pc-1.2</machine>\n        <machine maxCpus='1'>isapc</machine>\n        <machine maxCpus='255'>pc-q35-1.4</machine>\n        <machine maxCpus='128'>xenfv</machine>\n        <machine maxCpus='255'>pc-0.15</machine>\n        <machine maxCpus='255'>pc-i440fx-1.5</machine>\n        <machine maxCpus='255'>pc-i440fx-1.4</machine>\n        <machine maxCpus='255'>pc-q35-2.0</machine>\n        <machine maxCpus='255'>pc-0.14</machine>\n        <machine maxCpus='255'>pc-1.1</machine>\n        <machine maxCpus='255'>pc-q35-1.7</machine>\n        <machine maxCpus='255'>pc-i440fx-2.1</machine>\n        <machine maxCpus='255'>pc-1.0</machine>\n        <machine maxCpus='255'>pc-i440fx-2.0</machine>\n        <machine maxCpus='255'>pc-0.13</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n      <acpi default='on' toggle='yes'/>\n      <apic default='on' toggle='no'/>\n    </features>\n  </guest>\n\n</capabilities>\n---------------------"
					},
					{
						"isprivate": "0",
						"commentid": "7714536",
						"comment_count": "3",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-11-27 15:29:07 +0000",
						"thetext": "Created attachment 962119\n`virsh dumpxml` of DevStack VM where OpenStack setup is running."
					},
					{
						"isprivate": "0",
						"commentid": "7714555",
						"comment_count": "4",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-11-27 15:33:39 +0000",
						"thetext": "Created attachment 962126\nlibvirt XML Nova attempted to set when tried to boot an instance, but failed. Obtained from DevStack screen-n-cpu.log.\n\nContextual snippet from the attachment:\n\n[. . .]\n  <memory>1048576</memory>\n  <numatune>\n    <memory mode=\"strict\" nodeset=\"0\"/>\n    <memnode cellid=\"0\" mode=\"strict\" nodeset=\"0\"/>\n  </numatune>\n  <vcpu>4</vcpu>\n  <metadata>\n    <nova:instance xmlns:nova=\"http://openstack.org/xmlns/libvirt/nova/1.0\">\n      <nova:package version=\"2015.1\"/>\n      <nova:name>cirrvm3</nova:name>\n      <nova:creationTime>2014-11-27 14:18:18</nova:creationTime>\n      <nova:flavor name=\"m1.numa\">\n        <nova:memory>1024</nova:memory>\n        <nova:disk>1</nova:disk>\n        <nova:swap>0</nova:swap>\n        <nova:ephemeral>0</nova:ephemeral>\n        <nova:vcpus>4</nova:vcpus>\n      </nova:flavor>\n      <nova:owner>\n        <nova:user uuid=\"e2ab0e48d003456da53e892366651175\">admin</nova:user>\n        <nova:project uuid=\"a9a2cd5511214089a290ccfcac47502c\">admin</nova:project>\n      </nova:owner>\n      <nova:root type=\"image\" uuid=\"178c675a-d5fb-459f-a850-f7ffa6e2c9d2\"/>\n    </nova:instance>\n  </metadata>\n[. . .]\n  <cputune>\n    <emulatorpin cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"0\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"1\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"2\" cpuset=\"0-3\"/>\n    <vcpupin vcpu=\"3\" cpuset=\"0-3\"/>\n  </cputune>\n[. . .]"
					},
					{
						"isprivate": "0",
						"commentid": "7714868",
						"comment_count": "5",
						"who": {
							"text": "ndipanov",
							"name": "Nikola Dipanov"
						},
						"bug_when": "2014-11-27 17:10:46 +0000",
						"thetext": "It might also be relevant that in this case, the domain XML will as well have a <numa> element specified."
					},
					{
						"isprivate": "0",
						"commentid": "7716635",
						"comment_count": "6",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-11-28 12:58:58 +0000",
						"thetext": "Created attachment 962491\nAnother Nova instance XML (this time with <numa> attribute), attempted to set by Nova libvirt driver\n\nContextual snippet of Nova guest XML:\n[. . .]\n  <vcpu placement='static'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='0-3'/>\n    <vcpupin vcpu='1' cpuset='0-3'/>\n    <vcpupin vcpu='2' cpuset='0-3'/>\n    <vcpupin vcpu='3' cpuset='0-3'/>\n    <emulatorpin cpuset='0-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n    <memnode cellid='0' mode='strict' nodeset='0'/>\n  </numatune>\n[. . .]\n  <cpu>\n    <topology sockets='4' cores='1' threads='1'/>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576'/>\n    </numa>\n  </cpu>\n[. . .]\n\n\nI was here in Nova's git when I tested this time:\n\n  nova]$ git describe\n  2014.2-995-g5d2ea10\n\n\nPreviously, I was at:\n\n  nova]$ git describe\n  2014.2-973-g922ca3c"
					},
					{
						"isprivate": "0",
						"commentid": "7716834",
						"comment_count": "7",
						"who": {
							"text": "mkletzan",
							"name": "Martin Kletzander"
						},
						"bug_when": "2014-11-28 13:31:01 +0000",
						"thetext": "Fixed upstream with v1.2.10-75-gc6e9024:\n\ncommit c6e90248676126c209b3b6017ad27cf6c6a0ab8f\nAuthor: Wang Rui <moon.wangrui@huawei.com>\nDate:   Mon Nov 10 21:53:19 2014 +0800\n\n    qemu: fix domain startup failing with 'strict' mode in numatune"
					},
					{
						"isprivate": "0",
						"commentid": "7717350",
						"comment_count": "8",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-11-28 18:49:23 +0000",
						"thetext": "Tested with libvirt RPMs built from git:\n\n  $ git describe\n  CVE-2014-7823-193-g6085d91\n\n  $ git rev-parse --short HEAD\n  6085d91\n\nwhich has the commit mentioned in comment #7. \n\nRe-testing Nova with these RPMs (libvirt-1.2.11 -- yet to be released) version, Nova instance with NUMA topology boots successfully:\n\n1. Create a Nova flavor with NUMA topology: \n\n    $ nova flavor-create m1.numa 999 1024 1 4\n    $ nova flavor-key m1.numa set hw:numa_nodes=1\n    $ nova flavor-show m1.numa\n    +----------------------------+------------------------+\n    | Property                   | Value                  |\n    +----------------------------+------------------------+\n    | OS-FLV-DISABLED:disabled   | False                  |\n    | OS-FLV-EXT-DATA:ephemeral  | 0                      |\n    | disk                       | 1                      |\n    | extra_specs                | {\"hw:numa_nodes\": \"1\"} |\n    | id                         | 999                    |\n    | name                       | m1.numa                |\n    | os-flavor-access:is_public | True                   |\n    | ram                        | 1024                   |\n    | rxtx_factor                | 1.0                    |\n    | swap                       |                        |\n    | vcpus                      | 4                      |\n    +----------------------------+------------------------+\n\n\n2. Boot a Nova guest:\n\n$ nova boot --image cirros-0.3.1-x86_64-disk --flavor m1.numa cirrvm5\n\n\n3. Find the Nova instance:\n\n$ nova list | grep cirrvm5\n| 5d4c50ff-301c-44cb-826f-ffa07266d85f | cirrvm5 | ACTIVE | -          | Running     | public=172.24.4.6 |\n\n\n4. Find the libvirt ID for the Nova instance:\n\n$ grep -i 5d4c50ff-301c-44cb-826f-ffa07266d85f /etc/libvirt/qemu/*.xml | grep uuid\n/etc/libvirt/qemu/instance-00000004.xml:  <uuid>5d4c50ff-301c-44cb-826f-ffa07266d85f</uuid>\n[. . .]\n\n\n5. Examine Nova instance's libvirt XML:\n\n--------------------\n$ sudo virsh dumpxml instance-00000004\n<domain type='kvm' id='3'>\n  <name>instance-00000004</name>\n  <uuid>5d4c50ff-301c-44cb-826f-ffa07266d85f</uuid>\n  <metadata>\n    <nova:instance xmlns:nova=\"http://openstack.org/xmlns/libvirt/nova/1.0\">\n      <nova:package version=\"2015.1\"/>\n      <nova:name>cirrvm5</nova:name>\n      <nova:creationTime>2014-11-28 18:11:27</nova:creationTime>\n      <nova:flavor name=\"m1.numa\">\n        <nova:memory>1024</nova:memory>\n        <nova:disk>1</nova:disk>\n        <nova:swap>0</nova:swap>\n        <nova:ephemeral>0</nova:ephemeral>\n        <nova:vcpus>4</nova:vcpus>\n      </nova:flavor>\n      <nova:owner>\n        <nova:user uuid=\"f9a0644c9e9540828fbd8249dc9a92a2\">admin</nova:user>\n        <nova:project uuid=\"9157c0a4cf194d02bb4aa8023fb9db8b\">admin</nova:project>\n      </nova:owner>\n      <nova:root type=\"image\" uuid=\"e15c9d88-5de0-4f4b-8d15-708cd32f4ea9\"/>\n    </nova:instance>\n  </metadata>\n  <memory unit='KiB'>1048576</memory>\n  <currentMemory unit='KiB'>1048576</currentMemory>\n  <vcpu placement='static'>4</vcpu>\n  <cputune>\n    <vcpupin vcpu='0' cpuset='0-3'/>\n    <vcpupin vcpu='1' cpuset='0-3'/>\n    <vcpupin vcpu='2' cpuset='0-3'/>\n    <vcpupin vcpu='3' cpuset='0-3'/>\n    <emulatorpin cpuset='0-3'/>\n  </cputune>\n  <numatune>\n    <memory mode='strict' nodeset='0'/>\n    <memnode cellid='0' mode='strict' nodeset='0'/>\n  </numatune>\n  <resource>\n    <partition>/machine</partition>\n  </resource>\n  <sysinfo type='smbios'>\n    <system>\n      <entry name='manufacturer'>OpenStack Foundation</entry>\n      <entry name='product'>OpenStack Nova</entry>\n      <entry name='version'>2015.1</entry>\n      <entry name='serial'>bf6b5391-2390-df4f-b3dc-aa80d05468bb</entry>\n      <entry name='uuid'>5d4c50ff-301c-44cb-826f-ffa07266d85f</entry>\n    </system>\n  </sysinfo>\n  <os>\n    <type arch='x86_64' machine='pc-i440fx-2.2'>hvm</type>\n    <boot dev='hd'/>\n    <smbios mode='sysinfo'/>\n  </os>\n  <features>\n    <acpi/>\n    <apic/>\n  </features>\n  <cpu>\n    <topology sockets='4' cores='1' threads='1'/>\n    <numa>\n      <cell id='0' cpus='0-3' memory='1048576' unit='KiB'/>\n    </numa>\n  </cpu>\n  <clock offset='utc'>\n    <timer name='pit' tickpolicy='delay'/>\n    <timer name='rtc' tickpolicy='catchup'/>\n    <timer name='hpet' present='no'/>\n  </clock>\n  <on_poweroff>destroy</on_poweroff>\n  <on_reboot>restart</on_reboot>\n  <on_crash>destroy</on_crash>\n  <devices>\n    <emulator>/usr/bin/qemu-kvm</emulator>\n    <disk type='file' device='disk'>\n      <driver name='qemu' type='qcow2' cache='none'/>\n      <source file='/home/kashyapc/src/cloud/data/nova/instances/5d4c50ff-301c-44cb-826f-ffa07266d85f/disk'/>\n      <backingStore type='file' index='1'>\n        <format type='raw'/>\n        <source file='/home/kashyapc/src/cloud/data/nova/instances/_base/f187eddcdb76fcfd896c0916b9288e666014ce2b'/>\n        <backingStore/>\n      </backingStore>\n      <target dev='vda' bus='virtio'/>\n      <alias name='virtio-disk0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\n    </disk>\n    <disk type='file' device='cdrom'>\n      <driver name='qemu' type='raw' cache='none'/>\n      <source file='/home/kashyapc/src/cloud/data/nova/instances/5d4c50ff-301c-44cb-826f-ffa07266d85f/disk.config'/>\n      <backingStore/>\n      <target dev='hdd' bus='ide'/>\n      <readonly/>\n      <alias name='ide0-1-1'/>\n      <address type='drive' controller='0' bus='1' target='0' unit='1'/>\n    </disk>\n    <controller type='usb' index='0'>\n      <alias name='usb0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x2'/>\n    </controller>\n    <controller type='pci' index='0' model='pci-root'>\n      <alias name='pci.0'/>\n    </controller>\n    <controller type='ide' index='0'>\n      <alias name='ide0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\n    </controller>\n    <interface type='bridge'>\n      <mac address='fa:16:3e:fd:50:8f'/>\n      <source bridge='qbr1ee94b1e-29'/>\n      <target dev='tap1ee94b1e-29'/>\n      <model type='virtio'/>\n      <alias name='net0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\n    </interface>\n    <serial type='file'>\n      <source path='/home/kashyapc/src/cloud/data/nova/instances/5d4c50ff-301c-44cb-826f-ffa07266d85f/console.log'/>\n      <target port='0'/>\n      <alias name='serial0'/>\n    </serial>\n    <serial type='pty'>\n      <source path='/dev/pts/17'/>\n      <target port='1'/>\n      <alias name='serial1'/>\n    </serial>\n    <console type='file'>\n      <source path='/home/kashyapc/src/cloud/data/nova/instances/5d4c50ff-301c-44cb-826f-ffa07266d85f/console.log'/>\n      <target type='serial' port='0'/>\n      <alias name='serial0'/>\n    </console>\n    <memballoon model='virtio'>\n      <alias name='balloon0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\n      <stats period='10'/>\n    </memballoon>\n  </devices>\n  <seclabel type='dynamic' model='selinux' relabel='yes'>\n    <label>system_u:system_r:svirt_t:s0:c176,c615</label>\n    <imagelabel>system_u:object_r:svirt_image_t:s0:c176,c615</imagelabel>\n  </seclabel>\n</domain>\n--------------------\n\n6. Check what Nova recorded in the database (PostgreSQL in this case):\n\n$  sudo -u postgres psql nova\nnova=#\nnova=# SELECT numa_topology FROM instance_extra;\n[. . .]\n {\"nova_object.version\": \"1.1\", \"nova_object.changes\": [\"instance_uuid\"], \"nova_object.name\": \"InstanceNUMATopology\", \"nova_object.data\": {\"instance_u\nuid\": \"5d4c50ff-301c-44cb-826f-ffa07266d85f\", \"cells\": [{\"nova_object.version\": \"1.1\", \"nova_object.changes\": [\"cpuset\", \"id\", \"pagesize\", \"memory\"], \n\"nova_object.name\": \"InstanceNUMACell\", \"nova_object.data\": {\"cpuset\": [0, 1, 2, 3], \"id\": 0, \"pagesize\": null, \"memory\": 1024}, \"nova_object.namespac\ne\": \"nova\"}]}, \"nova_object.namespace\": \"nova\"}"
					},
					{
						"isprivate": "0",
						"commentid": "7754408",
						"comment_count": "9",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2014-12-11 09:13:31 +0000",
						"thetext": "Additional info\n---------------\n\nQEMU CLI of the Nova guest booted with a single NUMA node:\n\n-----------------------------------------------------------------------\n/usr/bin/qemu-system-x86_64 -machine accel=kvm -name instance-00000001 -S -machine pc-i440fx-2.2,accel=kvm,usb=off -m 1024 -realtime mlock=off -smp 4,sockets=4,cores=1,threads=1 -object memory-backend-ram,size=1024M,id=ram-node0,host-nodes=0,policy=bind -numa node,nodeid=0,cpus=0-3,memdev=ram-node0 -uuid 7646f836-7cb4-4f8b-bb69-ce4976af1081 -smbios type=1,manufacturer=OpenStack Foundation,product=OpenStack Nova,version=2015.1,serial=7dae2ee3-8950-9a41-9e24-a463a8563bbd,uuid=7646f836-7cb4-4f8b-bb69-ce4976af1081 -nographic -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/instance-00000001.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew -global kvm-pit.lost_tick_policy=discard -no-hpet -no-shutdown -boot strict=on -device piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2 -drive file=/home/kashyapc/src/cloud/data/nova/instances/7646f836-7cb4-4f8b-bb69-ce4976af1081/disk,if=none,id=drive-virtio-disk0,format=qcow2,cache=none -device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x3,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=1 -drive file=/home/kashyapc/src/cloud/data/nova/instances/7646f836-7cb4-4f8b-bb69-ce4976af1081/disk.config,if=none,id=drive-ide0-1-1,readonly=on,format=raw,cache=none -device ide-cd,bus=ide.1,unit=1,drive=drive-ide0-1-1,id=ide0-1-1 -netdev tap,fd=24,id=hostnet0,vhost=on,vhostfd=25 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=fa:16:3e:77:84:88,bus=pci.0,addr=0x2 -chardev file,id=charserial0,path=/home/kashyapc/src/cloud/data/nova/instances/7646f836-7cb4-4f8b-bb69-ce4976af1081/console.log -device isa-serial,chardev=charserial0,id=serial0 -chardev pty,id=charserial1 -device isa-serial,chardev=charserial1,id=serial1 -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4 -msg timestamp=on\n-----------------------------------------------------------------------"
					},
					{
						"isprivate": "0",
						"commentid": "7917101",
						"comment_count": "10",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-08 16:34:14 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been submitted as an update for Fedora 21.\nhttps://admin.fedoraproject.org/updates/libvirt-1.2.9.2-1.fc21"
					},
					{
						"isprivate": "0",
						"commentid": "7918210",
						"comment_count": "11",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-09 05:32:08 +0000",
						"thetext": "Package libvirt-1.2.9.2-1.fc21:\n* should fix your issue,\n* was pushed to the Fedora 21 testing repository,\n* should be available at your local mirror within two days.\nUpdate it with:\n# su -c 'yum update --enablerepo=updates-testing libvirt-1.2.9.2-1.fc21'\nas soon as you are able to.\nPlease go to the following url:\nhttps://admin.fedoraproject.org/updates/FEDORA-2015-1892/libvirt-1.2.9.2-1.fc21\nthen log in and leave karma (feedback)."
					},
					{
						"isprivate": "0",
						"commentid": "7938339",
						"comment_count": "12",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:21 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					}
				]
			}
		},
		{
			"bug_id": 1172569,
			"parent": true,
			"security": true,
			"title": "CVE-2014-8131 libvirt: deadlock and segfault in qemuConnectGetAllDomainStats",
			"bugzilla": {
				"bug_id": "1172569",
				"alias": "CVE-2014-8131",
				"creation_ts": "2014-12-10 11:39:34 +0000",
				"short_desc": "CVE-2014-8131 libvirt: deadlock and segfault in qemuConnectGetAllDomainStats",
				"delta_ts": "2021-02-17 05:54:39 +0000",
				"bug_status": "CLOSED",
				"resolution": "NOTABUG",
				"keywords": "Security",
				"priority": "low",
				"bug_severity": "low",
				"depends_on": [
					"1172570",
					"1172571"
				],
				"blocked": [
					{
						"bug_id": "1172575",
						"error": "NotPermitted"
					}
				],
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7750346",
						"comment_count": "0",
						"who": {
							"text": "pmatouse",
							"name": "Petr Matousek"
						},
						"bug_when": "2014-12-10 11:39:34 +0000",
						"thetext": "When user doesn't have read access on one of the domains he requested,\nthe for loop in qemuConnectGetAllDomainStats() could exit abruptly or\ncontinue and override pointer which pointed to locked object.\n\nWith certain configuration, this can either cause a deadlock (it leaves a\ndomain locked) or a segmentation fault when domain object has its reference\ncounter decremented when it was not incremented.\n\nWith certain configuration, a remote attacker able to establish a read-only\nconnection to libvirtd could use this flaw to caus denial of service condition\nor crash libvirtd.\n\nIntroduced by:\n\nhttp://libvirt.org/git/?p=libvirt.git;a=commit;h=d1bde8ed\nhttp://libvirt.org/git/?p=libvirt.git;a=commit;h=1f4831ee\n\nUpstream patches:\nhttps://www.redhat.com/archives/libvir-list/2014-December/msg00551.html\nhttps://www.redhat.com/archives/libvir-list/2014-December/msg00600.html"
					},
					{
						"isprivate": "0",
						"commentid": "7750354",
						"comment_count": "1",
						"who": {
							"text": "pmatouse",
							"name": "Petr Matousek"
						},
						"bug_when": "2014-12-10 11:40:08 +0000",
						"thetext": "Statement:\n\nNot vulnerable.\n\nThis issue does not affect the versions of libvirt packages as shipped with\nRed Hat Enterprise Linux 5, 6 and 7."
					},
					{
						"isprivate": "0",
						"commentid": "7750362",
						"comment_count": "3",
						"who": {
							"text": "pmatouse",
							"name": "Petr Matousek"
						},
						"bug_when": "2014-12-10 11:40:57 +0000",
						"thetext": "\nCreated libvirt tracking bugs for this issue:\n\nAffects: fedora-all [bug 1172571]"
					},
					{
						"isprivate": "0",
						"commentid": "7805981",
						"comment_count": "4",
						"who": {
							"text": "pmatouse",
							"name": "Petr Matousek"
						},
						"bug_when": "2015-01-05 10:00:33 +0000",
						"thetext": "Upstream advisory:\n\nhttp://security.libvirt.org/2014/0008.html"
					},
					{
						"isprivate": "0",
						"commentid": "7938343",
						"comment_count": "5",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:51 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					}
				]
			}
		},
		{
			"bug_id": 1172571,
			"security": true,
			"title": "CVE-2014-8131  libvirt: deadlock and segfault in qemuConnectGetAllDomainStats [fedora-all]",
			"bugzilla": {
				"bug_id": "1172571",
				"creation_ts": "2014-12-10 11:40:43 +0000",
				"short_desc": "CVE-2014-8131  libvirt: deadlock and segfault in qemuConnectGetAllDomainStats [fedora-all]",
				"delta_ts": "2015-02-15 03:06:28 +0000",
				"bug_status": "CLOSED",
				"resolution": "ERRATA",
				"keywords": "Security, SecurityTracking",
				"priority": "low",
				"bug_severity": "low",
				"blocked": [
					{
						"bug_id": "1172569",
						"alias": "CVE-2014-8131",
						"creation_ts": "2014-12-10 11:39:34 +0000",
						"short_desc": "CVE-2014-8131 libvirt: deadlock and segfault in qemuConnectGetAllDomainStats",
						"delta_ts": "2021-02-17 05:54:39 +0000",
						"bug_status": "CLOSED",
						"resolution": "NOTABUG",
						"keywords": "Security",
						"priority": "low",
						"bug_severity": "low",
						"depends_on": [
							"1172570",
							"1172571"
						],
						"blocked": [
							{
								"bug_id": "1172575",
								"error": "NotPermitted"
							}
						],
						"long_desc": [
							{
								"isprivate": "0",
								"commentid": "7750346",
								"comment_count": "0",
								"who": {
									"text": "pmatouse",
									"name": "Petr Matousek"
								},
								"bug_when": "2014-12-10 11:39:34 +0000",
								"thetext": "When user doesn't have read access on one of the domains he requested,\nthe for loop in qemuConnectGetAllDomainStats() could exit abruptly or\ncontinue and override pointer which pointed to locked object.\n\nWith certain configuration, this can either cause a deadlock (it leaves a\ndomain locked) or a segmentation fault when domain object has its reference\ncounter decremented when it was not incremented.\n\nWith certain configuration, a remote attacker able to establish a read-only\nconnection to libvirtd could use this flaw to caus denial of service condition\nor crash libvirtd.\n\nIntroduced by:\n\nhttp://libvirt.org/git/?p=libvirt.git;a=commit;h=d1bde8ed\nhttp://libvirt.org/git/?p=libvirt.git;a=commit;h=1f4831ee\n\nUpstream patches:\nhttps://www.redhat.com/archives/libvir-list/2014-December/msg00551.html\nhttps://www.redhat.com/archives/libvir-list/2014-December/msg00600.html"
							},
							{
								"isprivate": "0",
								"commentid": "7750354",
								"comment_count": "1",
								"who": {
									"text": "pmatouse",
									"name": "Petr Matousek"
								},
								"bug_when": "2014-12-10 11:40:08 +0000",
								"thetext": "Statement:\n\nNot vulnerable.\n\nThis issue does not affect the versions of libvirt packages as shipped with\nRed Hat Enterprise Linux 5, 6 and 7."
							},
							{
								"isprivate": "0",
								"commentid": "7750362",
								"comment_count": "3",
								"who": {
									"text": "pmatouse",
									"name": "Petr Matousek"
								},
								"bug_when": "2014-12-10 11:40:57 +0000",
								"thetext": "\nCreated libvirt tracking bugs for this issue:\n\nAffects: fedora-all [bug 1172571]"
							},
							{
								"isprivate": "0",
								"commentid": "7805981",
								"comment_count": "4",
								"who": {
									"text": "pmatouse",
									"name": "Petr Matousek"
								},
								"bug_when": "2015-01-05 10:00:33 +0000",
								"thetext": "Upstream advisory:\n\nhttp://security.libvirt.org/2014/0008.html"
							},
							{
								"isprivate": "0",
								"commentid": "7938343",
								"comment_count": "5",
								"who": {
									"text": "updates",
									"name": "Fedora Update System"
								},
								"bug_when": "2015-02-15 03:06:51 +0000",
								"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
							}
						]
					}
				],
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7750359",
						"comment_count": "0",
						"who": {
							"text": "pmatouse",
							"name": "Petr Matousek"
						},
						"bug_when": "2014-12-10 11:40:43 +0000",
						"thetext": "\nThis is an automatically created tracking bug!  It was created to ensure\nthat one or more security vulnerabilities are fixed in affected versions\nof Fedora.\n\nFor comments that are specific to the vulnerability please use bugs filed\nagainst the \"Security Response\" product referenced in the \"Blocks\" field.\n\nFor more information see:\nhttp://fedoraproject.org/wiki/Security/TrackingBugs\n\nWhen submitting as an update, use the fedpkg template provided in the next\ncomment(s).  This will include the bug IDs of this tracking bug as well as\nthe relevant top-level CVE bugs.\n\nPlease also mention the CVE IDs being fixed in the RPM changelog and the\nfedpkg commit message.\n\nNOTE: this issue affects multiple supported versions of Fedora. While only\none tracking bug has been filed, please correct all affected versions at\nthe same time.  If you need to fix the versions independent of each other,\nyou may clone this bug as appropriate.\n\n[bug automatically created by: add-tracking-bugs]"
					},
					{
						"isprivate": "0",
						"commentid": "7750360",
						"comment_count": "1",
						"who": {
							"text": "pmatouse",
							"name": "Petr Matousek"
						},
						"bug_when": "2014-12-10 11:40:50 +0000",
						"thetext": "\nUse the following template to for the 'fedpkg update' request to submit an\nupdate for this issue as it contains the top-level parent bug(s) as well as\nthis tracking bug.  This will ensure that all associated bugs get updated\nwhen new packages are pushed to stable.\n\n=====\n\n# bugfix, security, enhancement, newpackage (required)\ntype=security\n\n# testing, stable\nrequest=testing\n\n# Bug numbers: 1234,9876\nbugs=1172569,1172571\n\n# Description of your update\nnotes=Security fix for CVE-2014-8131\n\n# Enable request automation based on the stable/unstable karma thresholds\nautokarma=True\nstable_karma=3\nunstable_karma=-3\n\n# Automatically close bugs when this marked as stable\nclose_bugs=True\n\n# Suggest that users restart after update\nsuggest_reboot=False\n\n======\n\nAdditionally, you may opt to use the bodhi update submission link instead:\n\nhttps://admin.fedoraproject.org/updates/new/?type_=security&bugs=1172569,1172571"
					},
					{
						"isprivate": "0",
						"commentid": "7917104",
						"comment_count": "2",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-08 16:34:18 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been submitted as an update for Fedora 21.\nhttps://admin.fedoraproject.org/updates/libvirt-1.2.9.2-1.fc21"
					},
					{
						"isprivate": "0",
						"commentid": "7918211",
						"comment_count": "3",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-09 05:32:17 +0000",
						"thetext": "Package libvirt-1.2.9.2-1.fc21:\n* should fix your issue,\n* was pushed to the Fedora 21 testing repository,\n* should be available at your local mirror within two days.\nUpdate it with:\n# su -c 'yum update --enablerepo=updates-testing libvirt-1.2.9.2-1.fc21'\nas soon as you are able to.\nPlease go to the following url:\nhttps://admin.fedoraproject.org/updates/FEDORA-2015-1892/libvirt-1.2.9.2-1.fc21\nthen log in and leave karma (feedback)."
					},
					{
						"isprivate": "0",
						"commentid": "7938340",
						"comment_count": "4",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:28 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					}
				]
			}
		},
		{
			"bug_id": 1176176,
			"parent": true,
			"security": true,
			"title": "CVE-2014-8136 libvirt: local denial of service in qemu/qemu_driver.c",
			"bugzilla": {
				"bug_id": "1176176",
				"alias": "CVE-2014-8136",
				"creation_ts": "2014-12-19 15:54:27 +0000",
				"short_desc": "CVE-2014-8136 libvirt: local denial of service in qemu/qemu_driver.c",
				"delta_ts": "2019-09-29 13:25:32 +0000",
				"bug_status": "CLOSED",
				"resolution": "ERRATA",
				"keywords": "Security",
				"priority": "low",
				"bug_severity": "low",
				"depends_on": [
					"1176179",
					"1184407"
				],
				"blocked": [
					{
						"bug_id": "1176178",
						"error": "NotPermitted"
					}
				],
				"external_bugs": {
					"text": "RHSA-2015:0323",
					"name": "Red Hat Product Errata"
				},
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7781561",
						"comment_count": "0",
						"who": {
							"text": "vkaigoro",
							"name": "Vasyl Kaigorodov"
						},
						"bug_when": "2014-12-19 15:54:27 +0000",
						"thetext": "Common Vulnerabilities and Exposures assigned an identifier CVE-2014-8136 to\nthe following vulnerability:\n\nName: CVE-2014-8136\nURL: http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-8136\nAssigned: 20141010\nReference: http://secunia.com/advisories/61111\n\nThe (1) qemuDomainMigratePerform and (2) qemuDomainMigrateFinish2\nfunctions in qemu/qemu_driver.c in libvirt do not unlock the domain\nwhen an ACL check fails, which allow local users to cause a denial of\nservice via unspecified vectors.\n\nUpstream commit that addresses this:\nhttp://libvirt.org/git/?p=libvirt.git;a=commit;h=2bdcd29c713dfedd813c89f56ae98f6f3898313d"
					},
					{
						"isprivate": "0",
						"commentid": "7781595",
						"comment_count": "1",
						"who": {
							"text": "vkaigoro",
							"name": "Vasyl Kaigorodov"
						},
						"bug_when": "2014-12-19 15:57:24 +0000",
						"thetext": "\nCreated libvirt tracking bugs for this issue:\n\nAffects: fedora-all [bug 1176179]"
					},
					{
						"isprivate": "0",
						"commentid": "7845255",
						"comment_count": "4",
						"who": {
							"text": "eblake",
							"name": "Eric Blake"
						},
						"bug_when": "2015-01-14 18:52:18 +0000",
						"thetext": "See also the upstream announcement:\nhttp://security.libvirt.org/2014/0010.html"
					},
					{
						"isprivate": "0",
						"commentid": "7938345",
						"comment_count": "6",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:57 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					},
					{
						"isprivate": "0",
						"commentid": "7944065",
						"comment_count": "7",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-17 08:10:28 +0000",
						"thetext": "libvirt-1.1.3.9-1.fc20 has been pushed to the Fedora 20 stable repository.  If problems still persist, please make note of it in this bug report."
					},
					{
						"isprivate": "0",
						"commentid": "8009346",
						"comment_count": "8",
						"who": {
							"text": "errata-xmlrpc",
							"name": "errata-xmlrpc"
						},
						"bug_when": "2015-03-05 07:48:35 +0000",
						"thetext": "This issue has been addressed in the following products:\n\n  Red Hat Enterprise Linux 7\n\nVia RHSA-2015:0323 https://rhn.redhat.com/errata/RHSA-2015-0323.html"
					}
				]
			}
		},
		{
			"bug_id": 1176179,
			"security": true,
			"title": "CVE-2014-8136 libvirt: local denial of service in qemu/qemu_driver.c [fedora-all]",
			"bugzilla": {
				"bug_id": "1176179",
				"creation_ts": "2014-12-19 15:57:14 +0000",
				"short_desc": "CVE-2014-8136 libvirt: local denial of service in qemu/qemu_driver.c [fedora-all]",
				"delta_ts": "2015-02-17 08:10:23 +0000",
				"bug_status": "CLOSED",
				"resolution": "ERRATA",
				"keywords": "Security, SecurityTracking",
				"priority": "low",
				"bug_severity": "low",
				"blocked": [
					{
						"bug_id": "1176176",
						"alias": "CVE-2014-8136",
						"creation_ts": "2014-12-19 15:54:27 +0000",
						"short_desc": "CVE-2014-8136 libvirt: local denial of service in qemu/qemu_driver.c",
						"delta_ts": "2019-09-29 13:25:32 +0000",
						"bug_status": "CLOSED",
						"resolution": "ERRATA",
						"keywords": "Security",
						"priority": "low",
						"bug_severity": "low",
						"depends_on": [
							"1176179",
							"1184407"
						],
						"blocked": [
							{
								"bug_id": "1176178",
								"error": "NotPermitted"
							}
						],
						"external_bugs": {
							"text": "RHSA-2015:0323",
							"name": "Red Hat Product Errata"
						},
						"long_desc": [
							{
								"isprivate": "0",
								"commentid": "7781561",
								"comment_count": "0",
								"who": {
									"text": "vkaigoro",
									"name": "Vasyl Kaigorodov"
								},
								"bug_when": "2014-12-19 15:54:27 +0000",
								"thetext": "Common Vulnerabilities and Exposures assigned an identifier CVE-2014-8136 to\nthe following vulnerability:\n\nName: CVE-2014-8136\nURL: http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-8136\nAssigned: 20141010\nReference: http://secunia.com/advisories/61111\n\nThe (1) qemuDomainMigratePerform and (2) qemuDomainMigrateFinish2\nfunctions in qemu/qemu_driver.c in libvirt do not unlock the domain\nwhen an ACL check fails, which allow local users to cause a denial of\nservice via unspecified vectors.\n\nUpstream commit that addresses this:\nhttp://libvirt.org/git/?p=libvirt.git;a=commit;h=2bdcd29c713dfedd813c89f56ae98f6f3898313d"
							},
							{
								"isprivate": "0",
								"commentid": "7781595",
								"comment_count": "1",
								"who": {
									"text": "vkaigoro",
									"name": "Vasyl Kaigorodov"
								},
								"bug_when": "2014-12-19 15:57:24 +0000",
								"thetext": "\nCreated libvirt tracking bugs for this issue:\n\nAffects: fedora-all [bug 1176179]"
							},
							{
								"isprivate": "0",
								"commentid": "7845255",
								"comment_count": "4",
								"who": {
									"text": "eblake",
									"name": "Eric Blake"
								},
								"bug_when": "2015-01-14 18:52:18 +0000",
								"thetext": "See also the upstream announcement:\nhttp://security.libvirt.org/2014/0010.html"
							},
							{
								"isprivate": "0",
								"commentid": "7938345",
								"comment_count": "6",
								"who": {
									"text": "updates",
									"name": "Fedora Update System"
								},
								"bug_when": "2015-02-15 03:06:57 +0000",
								"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
							},
							{
								"isprivate": "0",
								"commentid": "7944065",
								"comment_count": "7",
								"who": {
									"text": "updates",
									"name": "Fedora Update System"
								},
								"bug_when": "2015-02-17 08:10:28 +0000",
								"thetext": "libvirt-1.1.3.9-1.fc20 has been pushed to the Fedora 20 stable repository.  If problems still persist, please make note of it in this bug report."
							},
							{
								"isprivate": "0",
								"commentid": "8009346",
								"comment_count": "8",
								"who": {
									"text": "errata-xmlrpc",
									"name": "errata-xmlrpc"
								},
								"bug_when": "2015-03-05 07:48:35 +0000",
								"thetext": "This issue has been addressed in the following products:\n\n  Red Hat Enterprise Linux 7\n\nVia RHSA-2015:0323 https://rhn.redhat.com/errata/RHSA-2015-0323.html"
							}
						]
					},
					{
						"bug_id": "1176182",
						"alias": "CVE-2014-8135",
						"creation_ts": "2014-12-19 16:01:14 +0000",
						"short_desc": "CVE-2014-8135 libvirt: local denial of service in storage/storage_driver.c",
						"delta_ts": "2021-02-17 05:52:43 +0000",
						"bug_status": "CLOSED",
						"resolution": "WONTFIX",
						"keywords": "Security",
						"priority": "medium",
						"bug_severity": "medium",
						"depends_on": [
							"1072653",
							"1087104",
							"1176179"
						],
						"blocked": [
							{
								"bug_id": "1176178",
								"error": "NotPermitted"
							}
						],
						"long_desc": [
							{
								"isprivate": "0",
								"commentid": "7781617",
								"comment_count": "0",
								"who": {
									"text": "vkaigoro",
									"name": "Vasyl Kaigorodov"
								},
								"bug_when": "2014-12-19 16:01:14 +0000",
								"thetext": "Common Vulnerabilities and Exposures assigned an identifier CVE-2014-8135 to\nthe following vulnerability:\n\nName: CVE-2014-8135\nURL: http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-8135\nAssigned: 20141010\nReference: http://secunia.com/advisories/61111\n\nThe storageVolUpload function in storage/storage_driver.c in libvirt\ndoes not check a certain return value, which allows local users to\ncause a denial of service (NULL pointer dereference and daemon crash)\nvia a crafted offset value in a \"virsh vol-upload\" command.\n\nUpstream commit that addresses this issue:\nhttp://libvirt.org/git/?p=libvirt.git;a=commit;h=87b9437f8951f9d24f9a85c6bbfff0e54df8c984"
							},
							{
								"isprivate": "0",
								"commentid": "7805987",
								"comment_count": "3",
								"who": {
									"text": "pmatouse",
									"name": "Petr Matousek"
								},
								"bug_when": "2015-01-05 10:01:59 +0000",
								"thetext": "Upstream advisory:\n\nhttp://security.libvirt.org/2014/0009.html"
							},
							{
								"isprivate": "0",
								"commentid": "8557539",
								"comment_count": "4",
								"who": {
									"text": "kseifried",
									"name": "Kurt Seifried"
								},
								"bug_when": "2015-08-19 22:30:08 +0000",
								"thetext": "Statement:\n\nThis issue affects the versions of libvirt as shipped with Red Hat Enterprise Linux 5, 6 and 7. Red Hat Product Security has rated this issue as having Moderate security impact. A future update may address this issue. For additional information, refer to the Issue Severity Classification: https://access.redhat.com/security/updates/classification/."
							}
						]
					}
				],
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7781591",
						"comment_count": "0",
						"who": {
							"text": "vkaigoro",
							"name": "Vasyl Kaigorodov"
						},
						"bug_when": "2014-12-19 15:57:14 +0000",
						"thetext": "\nThis is an automatically created tracking bug!  It was created to ensure\nthat one or more security vulnerabilities are fixed in affected versions\nof Fedora.\n\nFor comments that are specific to the vulnerability please use bugs filed\nagainst the \"Security Response\" product referenced in the \"Blocks\" field.\n\nFor more information see:\nhttp://fedoraproject.org/wiki/Security/TrackingBugs\n\nWhen submitting as an update, use the fedpkg template provided in the next\ncomment(s).  This will include the bug IDs of this tracking bug as well as\nthe relevant top-level CVE bugs.\n\nPlease also mention the CVE IDs being fixed in the RPM changelog and the\nfedpkg commit message.\n\nNOTE: this issue affects multiple supported versions of Fedora. While only\none tracking bug has been filed, please correct all affected versions at\nthe same time.  If you need to fix the versions independent of each other,\nyou may clone this bug as appropriate.\n\n[bug automatically created by: add-tracking-bugs]"
					},
					{
						"isprivate": "0",
						"commentid": "7781593",
						"comment_count": "1",
						"who": {
							"text": "vkaigoro",
							"name": "Vasyl Kaigorodov"
						},
						"bug_when": "2014-12-19 15:57:21 +0000",
						"thetext": "\nUse the following template to for the 'fedpkg update' request to submit an\nupdate for this issue as it contains the top-level parent bug(s) as well as\nthis tracking bug.  This will ensure that all associated bugs get updated\nwhen new packages are pushed to stable.\n\n=====\n\n# bugfix, security, enhancement, newpackage (required)\ntype=security\n\n# testing, stable\nrequest=testing\n\n# Bug numbers: 1234,9876\nbugs=1176176,1176179\n\n# Description of your update\nnotes=Security fix for CVE-2014-8136\n\n# Enable request automation based on the stable/unstable karma thresholds\nautokarma=True\nstable_karma=3\nunstable_karma=-3\n\n# Automatically close bugs when this marked as stable\nclose_bugs=True\n\n# Suggest that users restart after update\nsuggest_reboot=False\n\n======\n\nAdditionally, you may opt to use the bodhi update submission link instead:\n\nhttps://admin.fedoraproject.org/updates/new/?type_=security&bugs=1176176,1176179"
					},
					{
						"isprivate": "0",
						"commentid": "7788893",
						"comment_count": "2",
						"who": {
							"text": "eblake",
							"name": "Eric Blake"
						},
						"bug_when": "2014-12-23 22:57:56 +0000",
						"thetext": "The v1.1.3-maint (F20) and v1.2.9-maint (F21) branches now contains the fix, so the next build will pick it up for those builds; rawhide already has the fix by virtue of the fact that it uses 1.2.11.  F19 is not impacted."
					},
					{
						"isprivate": "0",
						"commentid": "7916702",
						"comment_count": "3",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-08 03:32:15 +0000",
						"thetext": "libvirt-1.1.3.9-1.fc20 has been submitted as an update for Fedora 20.\nhttps://admin.fedoraproject.org/updates/libvirt-1.1.3.9-1.fc20"
					},
					{
						"isprivate": "0",
						"commentid": "7917108",
						"comment_count": "4",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-08 16:34:24 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been submitted as an update for Fedora 21.\nhttps://admin.fedoraproject.org/updates/libvirt-1.2.9.2-1.fc21"
					},
					{
						"isprivate": "0",
						"commentid": "7918184",
						"comment_count": "5",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-09 05:29:59 +0000",
						"thetext": "Package libvirt-1.1.3.9-1.fc20:\n* should fix your issue,\n* was pushed to the Fedora 20 testing repository,\n* should be available at your local mirror within two days.\nUpdate it with:\n# su -c 'yum update --enablerepo=updates-testing libvirt-1.1.3.9-1.fc20'\nas soon as you are able to.\nPlease go to the following url:\nhttps://admin.fedoraproject.org/updates/FEDORA-2015-1883/libvirt-1.1.3.9-1.fc20\nthen log in and leave karma (feedback)."
					},
					{
						"isprivate": "0",
						"commentid": "7938342",
						"comment_count": "6",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:39 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					},
					{
						"isprivate": "0",
						"commentid": "7944063",
						"comment_count": "7",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-17 08:10:23 +0000",
						"thetext": "libvirt-1.1.3.9-1.fc20 has been pushed to the Fedora 20 stable repository.  If problems still persist, please make note of it in this bug report."
					}
				]
			}
		},
		{
			"bug_id": 1184431,
			"parent": true,
			"security": true,
			"title": "CVE-2015-0236 libvirt: missing ACL check for the VIR_DOMAIN_XML_SECURE flag in save images and snapshots objects",
			"bugzilla": {
				"bug_id": "1184431",
				"alias": "CVE-2015-0236",
				"creation_ts": "2015-01-21 11:24:22 +0000",
				"short_desc": "CVE-2015-0236 libvirt: missing ACL check for the VIR_DOMAIN_XML_SECURE flag in save images and snapshots objects",
				"delta_ts": "2023-05-12 06:44:05 +0000",
				"bug_status": "CLOSED",
				"resolution": "ERRATA",
				"keywords": "Security",
				"priority": "low",
				"bug_severity": "low",
				"depends_on": [
					"1184076",
					"1185769"
				],
				"blocked": [
					{
						"bug_id": "1176178",
						"error": "NotPermitted"
					}
				],
				"external_bugs": {
					"text": "RHSA-2015:0323",
					"name": "Red Hat Product Errata"
				},
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7864636",
						"comment_count": "0",
						"who": {
							"text": "pmatouse",
							"name": "Petr Matousek"
						},
						"bug_when": "2015-01-21 11:24:22 +0000",
						"thetext": "The XML getters for for save images and snapshots objects don't check ACLs\nfor the VIR_DOMAIN_XML_SECURE flag and might possibly dump security sensitive\ninformation.\n\nA remote attacker able to establish a connection to libvirtd\ncould use this flaw to cause leak certain limited information from the\ndomain xml file.\n\nAcknowledgements:\n\nThis issue was found by Luyao Huang of Red Hat."
					},
					{
						"isprivate": "0",
						"commentid": "7871375",
						"comment_count": "1",
						"who": {
							"text": "eblake",
							"name": "Eric Blake"
						},
						"bug_when": "2015-01-22 22:22:06 +0000",
						"thetext": "Upstream security notice:\nhttp://security.libvirt.org/2015/0001.html"
					},
					{
						"isprivate": "0",
						"commentid": "7877129",
						"comment_count": "2",
						"who": {
							"text": "mprpic",
							"name": "Martin Prpič"
						},
						"bug_when": "2015-01-26 09:08:19 +0000",
						"thetext": "\nCreated libvirt tracking bugs for this issue:\n\nAffects: fedora-all [bug 1185769]"
					},
					{
						"isprivate": "0",
						"commentid": "7877132",
						"comment_count": "3",
						"who": {
							"text": "mprpic",
							"name": "Martin Prpič"
						},
						"bug_when": "2015-01-26 09:09:40 +0000",
						"thetext": "External References:\n\nhttp://security.libvirt.org/2015/0001.html"
					},
					{
						"isprivate": "0",
						"commentid": "7938344",
						"comment_count": "4",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:55 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					},
					{
						"isprivate": "0",
						"commentid": "7944064",
						"comment_count": "5",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-17 08:10:26 +0000",
						"thetext": "libvirt-1.1.3.9-1.fc20 has been pushed to the Fedora 20 stable repository.  If problems still persist, please make note of it in this bug report."
					},
					{
						"isprivate": "0",
						"commentid": "8009360",
						"comment_count": "6",
						"who": {
							"text": "errata-xmlrpc",
							"name": "errata-xmlrpc"
						},
						"bug_when": "2015-03-05 07:49:24 +0000",
						"thetext": "This issue has been addressed in the following products:\n\n  Red Hat Enterprise Linux 7\n\nVia RHSA-2015:0323 https://rhn.redhat.com/errata/RHSA-2015-0323.html"
					}
				]
			}
		},
		{
			"bug_id": 1185769,
			"security": true,
			"title": "CVE-2015-0236 libvirt: missing ACL check for the VIR_DOMAIN_XML_SECURE flag in save images and snapshots objects [fedora-all]",
			"bugzilla": {
				"bug_id": "1185769",
				"creation_ts": "2015-01-26 09:08:05 +0000",
				"short_desc": "CVE-2015-0236 libvirt: missing ACL check for the VIR_DOMAIN_XML_SECURE flag in save images and snapshots objects [fedora-all]",
				"delta_ts": "2015-02-17 08:10:20 +0000",
				"bug_status": "CLOSED",
				"resolution": "ERRATA",
				"keywords": "Security, SecurityTracking",
				"priority": "low",
				"bug_severity": "low",
				"blocked": [
					{
						"bug_id": "1184431",
						"alias": "CVE-2015-0236",
						"creation_ts": "2015-01-21 11:24:22 +0000",
						"short_desc": "CVE-2015-0236 libvirt: missing ACL check for the VIR_DOMAIN_XML_SECURE flag in save images and snapshots objects",
						"delta_ts": "2023-05-12 06:44:05 +0000",
						"bug_status": "CLOSED",
						"resolution": "ERRATA",
						"keywords": "Security",
						"priority": "low",
						"bug_severity": "low",
						"depends_on": [
							"1184076",
							"1185769"
						],
						"blocked": [
							{
								"bug_id": "1176178",
								"error": "NotPermitted"
							}
						],
						"external_bugs": {
							"text": "RHSA-2015:0323",
							"name": "Red Hat Product Errata"
						},
						"long_desc": [
							{
								"isprivate": "0",
								"commentid": "7864636",
								"comment_count": "0",
								"who": {
									"text": "pmatouse",
									"name": "Petr Matousek"
								},
								"bug_when": "2015-01-21 11:24:22 +0000",
								"thetext": "The XML getters for for save images and snapshots objects don't check ACLs\nfor the VIR_DOMAIN_XML_SECURE flag and might possibly dump security sensitive\ninformation.\n\nA remote attacker able to establish a connection to libvirtd\ncould use this flaw to cause leak certain limited information from the\ndomain xml file.\n\nAcknowledgements:\n\nThis issue was found by Luyao Huang of Red Hat."
							},
							{
								"isprivate": "0",
								"commentid": "7871375",
								"comment_count": "1",
								"who": {
									"text": "eblake",
									"name": "Eric Blake"
								},
								"bug_when": "2015-01-22 22:22:06 +0000",
								"thetext": "Upstream security notice:\nhttp://security.libvirt.org/2015/0001.html"
							},
							{
								"isprivate": "0",
								"commentid": "7877129",
								"comment_count": "2",
								"who": {
									"text": "mprpic",
									"name": "Martin Prpič"
								},
								"bug_when": "2015-01-26 09:08:19 +0000",
								"thetext": "\nCreated libvirt tracking bugs for this issue:\n\nAffects: fedora-all [bug 1185769]"
							},
							{
								"isprivate": "0",
								"commentid": "7877132",
								"comment_count": "3",
								"who": {
									"text": "mprpic",
									"name": "Martin Prpič"
								},
								"bug_when": "2015-01-26 09:09:40 +0000",
								"thetext": "External References:\n\nhttp://security.libvirt.org/2015/0001.html"
							},
							{
								"isprivate": "0",
								"commentid": "7938344",
								"comment_count": "4",
								"who": {
									"text": "updates",
									"name": "Fedora Update System"
								},
								"bug_when": "2015-02-15 03:06:55 +0000",
								"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
							},
							{
								"isprivate": "0",
								"commentid": "7944064",
								"comment_count": "5",
								"who": {
									"text": "updates",
									"name": "Fedora Update System"
								},
								"bug_when": "2015-02-17 08:10:26 +0000",
								"thetext": "libvirt-1.1.3.9-1.fc20 has been pushed to the Fedora 20 stable repository.  If problems still persist, please make note of it in this bug report."
							},
							{
								"isprivate": "0",
								"commentid": "8009360",
								"comment_count": "6",
								"who": {
									"text": "errata-xmlrpc",
									"name": "errata-xmlrpc"
								},
								"bug_when": "2015-03-05 07:49:24 +0000",
								"thetext": "This issue has been addressed in the following products:\n\n  Red Hat Enterprise Linux 7\n\nVia RHSA-2015:0323 https://rhn.redhat.com/errata/RHSA-2015-0323.html"
							}
						]
					}
				],
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7877127",
						"comment_count": "0",
						"who": {
							"text": "mprpic",
							"name": "Martin Prpič"
						},
						"bug_when": "2015-01-26 09:08:05 +0000",
						"thetext": "\nThis is an automatically created tracking bug!  It was created to ensure\nthat one or more security vulnerabilities are fixed in affected versions\nof Fedora.\n\nFor comments that are specific to the vulnerability please use bugs filed\nagainst the \"Security Response\" product referenced in the \"Blocks\" field.\n\nFor more information see:\nhttp://fedoraproject.org/wiki/Security/TrackingBugs\n\nWhen submitting as an update, use the fedpkg template provided in the next\ncomment(s).  This will include the bug IDs of this tracking bug as well as\nthe relevant top-level CVE bugs.\n\nPlease also mention the CVE IDs being fixed in the RPM changelog and the\nfedpkg commit message.\n\nNOTE: this issue affects multiple supported versions of Fedora. While only\none tracking bug has been filed, please correct all affected versions at\nthe same time.  If you need to fix the versions independent of each other,\nyou may clone this bug as appropriate.\n\n[bug automatically created by: add-tracking-bugs]"
					},
					{
						"isprivate": "0",
						"commentid": "7877128",
						"comment_count": "1",
						"who": {
							"text": "mprpic",
							"name": "Martin Prpič"
						},
						"bug_when": "2015-01-26 09:08:16 +0000",
						"thetext": "\nUse the following template to for the 'fedpkg update' request to submit an\nupdate for this issue as it contains the top-level parent bug(s) as well as\nthis tracking bug.  This will ensure that all associated bugs get updated\nwhen new packages are pushed to stable.\n\n=====\n\n# bugfix, security, enhancement, newpackage (required)\ntype=security\n\n# testing, stable\nrequest=testing\n\n# Bug numbers: 1234,9876\nbugs=1184431,1185769\n\n# Description of your update\nnotes=Security fix for CVE-2015-0236\n\n# Enable request automation based on the stable/unstable karma thresholds\nautokarma=True\nstable_karma=3\nunstable_karma=-3\n\n# Automatically close bugs when this marked as stable\nclose_bugs=True\n\n# Suggest that users restart after update\nsuggest_reboot=False\n\n======\n\nAdditionally, you may opt to use the bodhi update submission link instead:\n\nhttps://admin.fedoraproject.org/updates/new/?type_=security&bugs=1184431,1185769"
					},
					{
						"isprivate": "0",
						"commentid": "7916701",
						"comment_count": "2",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-08 03:32:11 +0000",
						"thetext": "libvirt-1.1.3.9-1.fc20 has been submitted as an update for Fedora 20.\nhttps://admin.fedoraproject.org/updates/libvirt-1.1.3.9-1.fc20"
					},
					{
						"isprivate": "0",
						"commentid": "7917107",
						"comment_count": "3",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-08 16:34:22 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been submitted as an update for Fedora 21.\nhttps://admin.fedoraproject.org/updates/libvirt-1.2.9.2-1.fc21"
					},
					{
						"isprivate": "0",
						"commentid": "7918183",
						"comment_count": "4",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-09 05:29:56 +0000",
						"thetext": "Package libvirt-1.1.3.9-1.fc20:\n* should fix your issue,\n* was pushed to the Fedora 20 testing repository,\n* should be available at your local mirror within two days.\nUpdate it with:\n# su -c 'yum update --enablerepo=updates-testing libvirt-1.1.3.9-1.fc20'\nas soon as you are able to.\nPlease go to the following url:\nhttps://admin.fedoraproject.org/updates/FEDORA-2015-1883/libvirt-1.1.3.9-1.fc20\nthen log in and leave karma (feedback)."
					},
					{
						"isprivate": "0",
						"commentid": "7938341",
						"comment_count": "5",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:34 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					},
					{
						"isprivate": "0",
						"commentid": "7944062",
						"comment_count": "6",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-17 08:10:20 +0000",
						"thetext": "libvirt-1.1.3.9-1.fc20 has been pushed to the Fedora 20 stable repository.  If problems still persist, please make note of it in this bug report."
					}
				]
			}
		},
		{
			"bug_id": 1188644,
			"title": "segfault at 0 ip 00007fed0cb2eb4c sp 00007fecf005fad0 error 4 in libvirt.so.0.1002.11[7fed0ca72000+363000]",
			"bugzilla": {
				"bug_id": "1188644",
				"creation_ts": "2015-02-03 13:20:17 +0000",
				"short_desc": "libvirtd crashes when storage pool contains a qcow file backed by \"nbd://localhost\" or other URI lacking the path component",
				"delta_ts": "2015-03-26 11:50:21 +0000",
				"bug_status": "CLOSED",
				"resolution": "ERRATA",
				"priority": "unspecified",
				"bug_severity": "unspecified",
				"blocked": [
					{
						"bug_id": "1189007",
						"creation_ts": "2015-02-04 08:06:32 +0000",
						"short_desc": "libvirtd crashes when storage pool contains a qcow file backed by \"nbd://localhost\" or other URI lacking the path component",
						"delta_ts": "2015-11-19 06:09:44 +0000",
						"bug_status": "CLOSED",
						"resolution": "ERRATA",
						"keywords": "ZStream",
						"priority": "high",
						"bug_severity": "high",
						"depends_on": [
							"1188644"
						],
						"blocked": [
							{
								"bug_id": "1195156",
								"creation_ts": "2015-02-23 09:36:42 +0000",
								"short_desc": "libvirtd crashes when storage pool contains a qcow file backed by \"nbd://localhost\" or other URI lacking the path component",
								"delta_ts": "2015-03-05 14:10:08 +0000",
								"bug_status": "CLOSED",
								"resolution": "ERRATA",
								"keywords": "ZStream",
								"priority": "high",
								"bug_severity": "high",
								"depends_on": [
									"1189007"
								],
								"external_bugs": {
									"text": "RHBA-2015:0625",
									"name": "Red Hat Product Errata"
								},
								"long_desc": [
									{
										"isprivate": "0",
										"commentid": "7966341",
										"comment_count": "0",
										"who": {
											"text": "jkurik",
											"name": "Jan Kurik"
										},
										"bug_when": "2015-02-23 09:36:42 +0000",
										"thetext": "This bug has been copied from bug #1189007 and has been proposed\nto be backported to 7.1 z-stream (EUS)."
									},
									{
										"isprivate": "0",
										"commentid": "7977784",
										"comment_count": "8",
										"who": {
											"text": "yanyang",
											"name": "Yang Yang"
										},
										"bug_when": "2015-02-26 05:38:28 +0000",
										"thetext": "Hi Peter,\nLibvirtd still crashes when a storage file backed by \"gluster://$IP\". It works well when storage file backed by \"nbd://localhost\", \"iscsi://$IP\" and \"rbd://$IP\".\n\nproduct version\nqemu-img-rhev-2.1.2-23.el7_1.1.x86_64\nkernel-3.10.0-229.el7.x86_64\nlibvirt-1.2.8-16.el7_1.1.x86_64\n\nSteps for verification:\n\n1. storage file backed by gluster://$IP\n\n# qemu-img create -f qcow2 /var/lib/libvirt/images/gluster.img 100M\nFormatting '/var/lib/libvirt/images/gluster.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n[root@rhel7 ~]# qemu-img rebase -u -f qcow2 -F raw -b gluster://10.66.4.164 /var/lib/libvirt/images/gluster.img \n[root@rhel7 ~]# qemu-img info /var/lib/libvirt/images/gluster.img\nimage: /var/lib/libvirt/images/gluster.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: gluster://10.66.4.164\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n[root@rhel7 ~]# virsh pool-refresh default\nerror: Failed to refresh pool default\nerror: End of file while reading data: Input/output error\nerror: Failed to reconnect to the hypervisor\n\n2. storage file backed by iscsi://$IP\n[root@ibm-x3650m4-04 ~]# qemu-img create -f qcow2 /var/lib/libvirt/images/iscsi.img 100M\nFormatting '/var/lib/libvirt/images/iscsi.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n[root@ibm-x3650m4-04 ~]# qemu-img rebase -u -f qcow2 -F raw -b iscsi://10.66.5.155 /var/lib/libvirt/images/iscsi.img\n[root@ibm-x3650m4-04 ~]# qemu-img info /var/lib/libvirt/images/iscsi.img\nimage: /var/lib/libvirt/images/iscsi.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: iscsi://10.66.5.155\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n[root@ibm-x3650m4-04 ~]# virsh pool-refresh default\nPool default refreshed\n\n[root@ibm-x3650m4-04 ~]# virsh vol-list default\n Name                 Path                                    \n------------------------------------------------------------------------------\n iscsi.img            /var/lib/libvirt/images/iscsi.img\n\n[root@ibm-x3650m4-04 ~]# virsh vol-dumpxml iscsi.img default\n<volume type='file'>\n  <name>iscsi.img</name>\n  <key>/var/lib/libvirt/images/iscsi.img</key>\n  <source>\n  </source>\n  <capacity unit='bytes'>104857600</capacity>\n  <allocation unit='bytes'>200704</allocation>\n  <target>\n    <path>/var/lib/libvirt/images/iscsi.img</path>\n    <format type='qcow2'/>\n    <permissions>\n      <mode>0644</mode>\n      <owner>0</owner>\n      <group>0</group>\n      <label>unconfined_u:object_r:virt_image_t:s0</label>\n    </permissions>\n    <timestamps>\n      <atime>1424927649.973662076</atime>\n      <mtime>1424927643.008717986</mtime>\n      <ctime>1424927643.008717986</ctime>\n    </timestamps>\n    <compat>1.1</compat>\n    <features/>\n  </target>\n  <backingStore>\n    <path>iscsi://10.66.5.155</path>\n    <format type='raw'/>\n  </backingStore>\n</volume>\n\n3. storage file backed by nbd://localhost\n[root@ibm-x3650m4-04 ~]# qemu-img create -f qcow2 /var/lib/libvirt/images/nbd.img 100M\nFormatting '/var/lib/libvirt/images/nbd.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n[root@ibm-x3650m4-04 ~]# qemu-img rebase -u -f qcow2 -F raw -b nbd://localhost /var/lib/libvirt/images/nbd.img\n[root@ibm-x3650m4-04 ~]# qemu-img info /var/lib/libvirt/images/nbd.img\nimage: /var/lib/libvirt/images/nbd.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: nbd://localhost\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n\n[root@ibm-x3650m4-04 ~]# virsh pool-refresh default\nPool default refreshed\n\n[root@ibm-x3650m4-04 ~]# virsh vol-dumpxml nbd.img default\n<volume type='file'>\n  <name>nbd.img</name>\n  <key>/var/lib/libvirt/images/nbd.img</key>\n  <source>\n  </source>\n  <capacity unit='bytes'>104857600</capacity>\n  <allocation unit='bytes'>200704</allocation>\n  <target>\n    <path>/var/lib/libvirt/images/nbd.img</path>\n    <format type='qcow2'/>\n    <permissions>\n      <mode>0644</mode>\n      <owner>0</owner>\n      <group>0</group>\n      <label>unconfined_u:object_r:virt_image_t:s0</label>\n    </permissions>\n    <timestamps>\n      <atime>1424927846.036182521</atime>\n      <mtime>1424927840.116169454</mtime>\n      <ctime>1424927840.116169454</ctime>\n    </timestamps>\n    <compat>1.1</compat>\n    <features/>\n  </target>\n  <backingStore>\n    <path>nbd://localhost</path>\n    <format type='raw'/>\n  </backingStore>\n</volume>\n\n4. storage file backed by rbd://localhost\n[root@ibm-x3650m4-04 ~]# qemu-img create -f qcow2 /var/lib/libvirt/images/rbd.img 100M\nFormatting '/var/lib/libvirt/images/rbd.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n[root@ibm-x3650m4-04 ~]# qemu-img rebase -u -f qcow2 -F raw -b rbd://localhost /var/lib/libvirt/images/rbd.img\n[root@ibm-x3650m4-04 ~]# qemu-img info /var/lib/libvirt/images/rbd.img\nimage: /var/lib/libvirt/images/rbd.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: rbd://localhost\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n[root@ibm-x3650m4-04 ~]# virsh pool-refresh default\nPool default refreshed\n\n[root@ibm-x3650m4-04 ~]# virsh vol-list default\n Name                 Path                                    \n------------------------------------------------------------------------------\n iscsi.img            /var/lib/libvirt/images/iscsi.img       \n nbd.img              /var/lib/libvirt/images/nbd.img         \n rbd.img              /var/lib/libvirt/images/rbd.img         \n\n[root@ibm-x3650m4-04 ~]# virsh vol-dumpxml rbd.img default\n<volume type='file'>\n  <name>rbd.img</name>\n  <key>/var/lib/libvirt/images/rbd.img</key>\n  <source>\n  </source>\n  <capacity unit='bytes'>104857600</capacity>\n  <allocation unit='bytes'>200704</allocation>\n  <target>\n    <path>/var/lib/libvirt/images/rbd.img</path>\n    <format type='qcow2'/>\n    <permissions>\n      <mode>0644</mode>\n      <owner>0</owner>\n      <group>0</group>\n      <label>unconfined_u:object_r:virt_image_t:s0</label>\n    </permissions>\n    <timestamps>\n      <atime>1424927985.093879693</atime>\n      <mtime>1424927975.260807880</mtime>\n      <ctime>1424927975.260807880</ctime>\n    </timestamps>\n    <compat>1.1</compat>\n    <features/>\n  </target>\n  <backingStore>\n    <path>rbd://localhost</path>\n    <format type='raw'/>\n  </backingStore>\n</volume>"
									},
									{
										"isprivate": "0",
										"commentid": "7978032",
										"comment_count": "10",
										"who": {
											"text": "yanyang",
											"name": "Yang Yang"
										},
										"bug_when": "2015-02-26 07:55:07 +0000",
										"thetext": "New a Bug 1196528 - Libvirtd crashes when a storage file backed by gluster protocol lacking path\n\nAs libvirtd does NOT crash when storage file backed by nbd protocol lacking path, mark it as verified."
									},
									{
										"isprivate": "0",
										"commentid": "8015079",
										"comment_count": "12",
										"who": {
											"text": "errata-xmlrpc",
											"name": "errata-xmlrpc"
										},
										"bug_when": "2015-03-05 14:10:08 +0000",
										"thetext": "Since the problem described in this bug report should be\nresolved in a recent advisory, it has been closed with a\nresolution of ERRATA.\n\nFor information on the advisory, and where to find the updated\nfiles, follow the link below.\n\nIf the solution does not work for you, open a new bug report.\n\nhttps://rhn.redhat.com/errata/RHBA-2015-0625.html"
									}
								]
							}
						],
						"external_bugs": {
							"text": "RHBA-2015:2202",
							"name": "Red Hat Product Errata"
						},
						"long_desc": [
							{
								"isprivate": "0",
								"commentid": "7906601",
								"comment_count": "0",
								"who": {
									"text": "pkrempa",
									"name": "Peter Krempa"
								},
								"bug_when": "2015-02-04 08:06:32 +0000",
								"thetext": "+++ This bug was initially created as a clone of Bug #1188644 +++\n\n\n\nVersion\n-------\nlibvirt-1.2.8-12.el7.x86_64\n\n\n\nReproducer\n----------\n1) create qcow file as with backing file path \"nbd://localhost\" or similar in the default pool\n   - cd /var/lib/libvirt/images/\n   - qemu-img create -f qcow2 backing 10M\n   - qemu-nbd -f qcow2 backing\n   - qemu-img create -f qcow2 -o backing_file=nbd://localhost nbd\n2) restart libvirtd\n   $ systemctl restart libvirtd\n\n\nActual Result\n-------------\nlibvirtd crashes\n\n\n--- Additional comment from Peter Krempa on 2015-02-04 08:47:54 CET ---\n\ncommit fdb80ed4f6563928b9942a0d1450e0c725aa6c06\nAuthor: Peter Krempa <pkrempa@redhat.com>\nDate:   Tue Feb 3 18:03:41 2015 +0100\n\n    util: storage: Fix parsing of nbd:// URI without path\n    \n    If a storage file would be backed with a NBD device without path\n    (nbd://localhost) libvirt would crash when parsing the backing path for\n    the disk as the URI structure's path element is NULL in such case but\n    the NBD parser would access it shamelessly.\n\nv1.2.12-74-gfdb80ed"
							},
							{
								"isprivate": "0",
								"commentid": "7907007",
								"comment_count": "1",
								"who": {
									"text": "shyu",
									"name": "Shanzhi Yu"
								},
								"bug_when": "2015-02-04 10:28:18 +0000",
								"thetext": "Easy to reproduce it\n# rpm -q libvirt \nlibvirt-1.2.8-15.el7.x86_64\n\n1. \n# qemu-img create /var/lib/libvirt/images/backing -f qcow2 10M \nFormatting '/var/lib/libvirt/images/backing', fmt=qcow2 size=10485760 encryption=off cluster_size=65536 lazy_refcounts=off\n\n2.\n# qemu-nbd -f qcow2  /var/lib/libvirt/images/backing \n\n3. \n# qemu-img create -f qcow2 /var/lib/libvirt/images/nbd -o backing_file=nbd://localhost \nFormatting '/var/lib/libvirt/images/nbd', fmt=qcow2 size=10485760 backing_file='nbd://localhost' encryption=off cluster_size=65536 lazy_refcounts=off \n\n4. \n# virsh pool-refresh default\nerror: failed to connect to the hypervisor\nerror: no valid connection\nerror: Cannot recv data: Connection reset by peer"
							},
							{
								"isprivate": "0",
								"commentid": "8232570",
								"comment_count": "4",
								"who": {
									"text": "yanyang",
									"name": "Yang Yang"
								},
								"bug_when": "2015-05-14 10:13:54 +0000",
								"thetext": "Verified on libvirt-1.2.15-2.el7.x86_64\n\nSteps\n1. storage file backed by gluster://$IP\n# qemu-img create -f qcow2 /var/lib/libvirt/images/gluster.img 100M\nFormatting '/var/lib/libvirt/images/gluster.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n[root@rhel7_test ~]# qemu-img rebase -u -f qcow2 -F raw -b gluster://10.66.4.164 /var/lib/libvirt/images/gluster.img\n[root@rhel7_test ~]# qemu-img info /var/lib/libvirt/images/gluster.img\nimage: /var/lib/libvirt/images/gluster.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: gluster://10.66.4.164\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n    corrupt: false\n[root@rhel7_test ~]# virsh pool-refresh default\nerror: Failed to refresh pool default\nerror: unsupported configuration: missing volume name and path for gluster volume\n\n2. storage file backed by iscsi://$IP\n# qemu-img create -f qcow2 /var/lib/libvirt/images/iscsi.img 100M\nFormatting '/var/lib/libvirt/images/iscsi.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n# qemu-img rebase -u -f qcow2 -F raw -b iscsi://10.66.5.155 /var/lib/libvirt/images/iscsi.img\n# qemu-img info /var/lib/libvirt/images/iscsi.img\nimage: /var/lib/libvirt/images/iscsi.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: iscsi://10.66.5.155\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n# virsh pool-refresh default\nPool default refreshed\n\n[root@ibm-x3650m4-04 ~]# virsh vol-list default\n Name                 Path                                    \n------------------------------------------------------------------------------\n iscsi.img            /var/lib/libvirt/images/iscsi.img\n\n# virsh vol-dumpxml iscsi.img default\n<volume type='file'>\n  <name>iscsi.img</name>\n  <key>/var/lib/libvirt/images/iscsi.img</key>\n  <source>\n  </source>\n  <capacity unit='bytes'>104857600</capacity>\n  <allocation unit='bytes'>200704</allocation>\n  <target>\n    <path>/var/lib/libvirt/images/iscsi.img</path>\n    <format type='qcow2'/>\n    <permissions>\n      <mode>0644</mode>\n      <owner>0</owner>\n      <group>0</group>\n      <label>unconfined_u:object_r:virt_image_t:s0</label>\n    </permissions>\n    <timestamps>\n      <atime>1424927649.973662076</atime>\n      <mtime>1424927643.008717986</mtime>\n      <ctime>1424927643.008717986</ctime>\n    </timestamps>\n    <compat>1.1</compat>\n    <features/>\n  </target>\n  <backingStore>\n    <path>iscsi://10.66.5.155</path>\n    <format type='raw'/>\n  </backingStore>\n</volume>\n\n3. storage file backed by nbd://localhost\n# qemu-img create -f qcow2 /var/lib/libvirt/images/nbd.img 100M\nFormatting '/var/lib/libvirt/images/nbd.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n[root@rhel7_test ~]# qemu-img rebase -u -f qcow2 -F raw -b nbd://localhost /var/lib/libvirt/images/nbd.img\n[root@rhel7_test ~]# qemu-img info /var/lib/libvirt/images/nbd.img\nimage: /var/lib/libvirt/images/nbd.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: nbd://localhost\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n    corrupt: false\n[root@rhel7_test ~]# virsh pool-refresh default\nPool default refreshed\n\n[root@rhel7_test ~]# virsh vol-info nbd.img default\nName:           nbd.img\nType:           file\nCapacity:       100.00 MiB\nAllocation:     196.00 KiB\n\n4.storage file backed by rbd://localhost\n# qemu-img create -f qcow2 /var/lib/libvirt/images/rbd.img 100M\nFormatting '/var/lib/libvirt/images/rbd.img', fmt=qcow2 size=104857600 encryption=off cluster_size=65536 lazy_refcounts=off \n[root@rhel7_test ~]# qemu-img rebase -u -f qcow2 -F raw -b rbd://localhost /var/lib/libvirt/images/rbd.img\n[root@rhel7_test ~]# qemu-img info /var/lib/libvirt/images/rbd.img\nimage: /var/lib/libvirt/images/rbd.img\nfile format: qcow2\nvirtual size: 100M (104857600 bytes)\ndisk size: 196K\ncluster_size: 65536\nbacking file: rbd://localhost\nbacking file format: raw\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n    corrupt: false\n[root@rhel7_test ~]# virsh pool-refresh default\nPool default refreshed\n\n[root@rhel7_test ~]# virsh vol-info rbd.img default\nName:           rbd.img\nType:           file\nCapacity:       100.00 MiB\nAllocation:     196.00 KiB"
							},
							{
								"isprivate": "0",
								"commentid": "8836247",
								"comment_count": "6",
								"who": {
									"text": "errata-xmlrpc",
									"name": "errata-xmlrpc"
								},
								"bug_when": "2015-11-19 06:09:44 +0000",
								"thetext": "Since the problem described in this bug report should be\nresolved in a recent advisory, it has been closed with a\nresolution of ERRATA.\n\nFor information on the advisory, and where to find the updated\nfiles, follow the link below.\n\nIf the solution does not work for you, open a new bug report.\n\nhttps://rhn.redhat.com/errata/RHBA-2015-2202.html"
							}
						]
					}
				],
				"long_desc": [
					{
						"isprivate": "0",
						"commentid": "7903648",
						"comment_count": "0",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2015-02-03 13:20:17 +0000",
						"thetext": "I noticed this in systemd Journal logs when I restarted libvirtd:\n\n\nFeb 03 12:33:16 tesla kernel: libvirtd[19169]: segfault at 0 ip 00007f265b231b4c sp 00007f263e762ad0 error 4 in libvirt.so.0.1002.11[7f265b175000+363000]\n\n\nVersion\n-------\n\n  $ uname -r; rpm -q libvirt qemu\n  3.17.8-300.fc21.x86_64\n  libvirt-1.2.11-1.fc21.x86_64\n  qemu-2.1.2-7.fc21.x86_64\n\n\nReproducer\n----------\n\nI can consistently reproduce this on my Fedora 21 laptop, just by restarting libvirtd\n\n   $ systemctl restart libvirtd\n\n\nActual Result\n-------------\n\nStatus of libvirt daemon:\n\n~~~~~~~\n$ systemctl status libvirtd -l\n● libvirtd.service - Virtualization daemon\n   Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled)\n   Active: failed (Result: start-limit) since Tue 2015-02-03 14:13:24 CET; 1min 53s ago\n     Docs: man:libvirtd(8)\n           http://libvirt.org\n  Process: 8562 ExecStart=/usr/sbin/libvirtd $LIBVIRTD_ARGS (code=killed, signal=SEGV)\n Main PID: 8562 (code=killed, signal=SEGV)\n   CGroup: /system.slice/libvirtd.service\n           ├─1857 /sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/openstackvms.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper\n           ├─1858 /sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/openstackvms.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper\n           ├─1986 /sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper\n           └─1987 /sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper\n\nFeb 03 14:13:23 tesla systemd[1]: libvirtd.service: main process exited, code=killed, status=11/SEGV\nFeb 03 14:13:23 tesla systemd[1]: Unit libvirtd.service entered failed state.\nFeb 03 14:13:23 tesla systemd[1]: libvirtd.service failed.\nFeb 03 14:13:24 tesla systemd[1]: start request repeated too quickly for libvirtd.service\nFeb 03 14:13:24 tesla systemd[1]: Failed to start Virtualization daemon.\nFeb 03 14:13:24 tesla systemd[1]: Unit libvirtd.service entered failed state.\nFeb 03 14:13:24 tesla systemd[1]: libvirtd.service failed.\n~~~~~~~\n\nFrom `journalctl`:\n\n$ journalctl -f\n\n[. . .]\nFeb 03 14:09:18 tesla dnsmasq[1986]: read /etc/hosts - 15 addresses\nFeb 03 14:09:18 tesla dnsmasq[1857]: read /etc/hosts - 15 addresses\nFeb 03 14:09:18 tesla dnsmasq[1986]: read /var/lib/libvirt/dnsmasq/default.addnhosts - 0 addresses\nFeb 03 14:09:18 tesla dnsmasq[1857]: read /var/lib/libvirt/dnsmasq/openstackvms.addnhosts - 0 addresses\nFeb 03 14:09:18 tesla dnsmasq-dhcp[1857]: read /var/lib/libvirt/dnsmasq/openstackvms.hostsfile\nFeb 03 14:09:18 tesla dnsmasq-dhcp[1986]: read /var/lib/libvirt/dnsmasq/default.hostsfile\nFeb 03 14:09:18 tesla kernel: SELinux: initialized (dev mqueue, type mqueue), uses transition SIDs\nFeb 03 14:09:18 tesla kernel: SELinux: initialized (dev proc, type proc), uses genfs_contexts\nFeb 03 14:09:18 tesla kernel: SELinux: initialized (dev mqueue, type mqueue), uses transition SIDs\nFeb 03 14:09:18 tesla kernel: SELinux: initialized (dev proc, type proc), uses genfs_contexts\nFeb 03 14:09:18 tesla kernel: libvirtd[23764]: segfault at 0 ip 00007f1e84aebb4c sp 00007f1e6801cad0 error 4 in libvirt.so.0.1002.11[7f1e84a2f000+363000]\nFeb 03 14:09:18 tesla abrt-hook-ccpp[23841]: Not saving repeating crash in '/usr/sbin/libvirtd'\nFeb 03 14:09:18 tesla systemd[1]: libvirtd.service: main process exited, code=killed, status=11/SEGV\nFeb 03 14:09:18 tesla systemd[1]: Unit libvirtd.service entered failed state.\nFeb 03 14:09:18 tesla systemd[1]: libvirtd.service failed.\nFeb 03 14:09:19 tesla systemd[1]: start request repeated too quickly for libvirtd.service\nFeb 03 14:09:19 tesla systemd[1]: Failed to start Virtualization daemon.\nFeb 03 14:09:19 tesla systemd[1]: Unit libvirtd.service entered failed state.\nFeb 03 14:09:19 tesla systemd[1]: libvirtd.service failed.\n[. . .]\n\n\nFailure from libvirt debug logs\n-------------------------------\n\n[. . .]\n2015-02-03 13:13:23.583+0000: 8573: debug : virPCIDeviceConfigOpen:312 : 8086 9c03 0000:00:1f.2: opened /sys/bus/pci/devices/0000:00:1f.2/config\n2015-02-03 13:13:23.583+0000: 8573: debug : virPCIDeviceFindCapabilityOffset:540 : 8086 9c03 0000:00:1f.2: failed to find cap 0x10\n2015-02-03 13:13:23.583+0000: 8573: debug : virPCIDeviceFindCapabilityOffset:533 : 8086 9c03 0000:00:1f.2: found cap 0x01 at 0x70\n2015-02-03 13:13:23.583+0000: 8573: debug : virPCIDeviceFindCapabilityOffset:540 : 8086 9c03 0000:00:1f.2: failed to find cap 0x13\n[. . .]"
					},
					{
						"isprivate": "0",
						"commentid": "7903713",
						"comment_count": "1",
						"who": {
							"text": "pkrempa",
							"name": "Peter Krempa"
						},
						"bug_when": "2015-02-03 13:30:51 +0000",
						"thetext": "Please attach a backtrace of the crash."
					},
					{
						"isprivate": "0",
						"commentid": "7904198",
						"comment_count": "2",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2015-02-03 15:10:32 +0000",
						"thetext": "There we go:\n\n\n$ gdb libvirtd $(pidof libvirtd)\nGNU gdb (GDB) Fedora 7.8.2-38.fc21\nCopyright (C) 2014 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-redhat-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n<http://www.gnu.org/software/gdb/bugs/>.\nFind the GDB manual and other documentation resources online at:\n<http://www.gnu.org/software/gdb/documentation/>.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from libvirtd...Reading symbols from /usr/lib/debug/usr/sbin/libvirtd.debug...done.\ndone.\n(gdb) r\nStarting program: /usr/sbin/libvirtd \n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\n2015-02-03 15:05:22.725+0000: 5728: info : libvirt version: 1.2.11, package: 1.fc21 (Unknown, 2014-12-13-04:59:24, intel-sharkbay-dh-07.ml3.eng.bos.redhat.com)\n2015-02-03 15:05:22.725+0000: 5728: debug : virLogParseOutputs:1104 : outputs=1:file:/var/log/libvirt/libvirtd.log\n[New Thread 0x7fffe7701700 (LWP 5732)]\n[New Thread 0x7fffe6f00700 (LWP 5733)]\n[New Thread 0x7fffe66ff700 (LWP 5734)]\n[New Thread 0x7fffe5efe700 (LWP 5735)]\n[New Thread 0x7fffe56fd700 (LWP 5736)]\n[New Thread 0x7fffe4efc700 (LWP 5737)]\n[New Thread 0x7fffe46fb700 (LWP 5738)]\n[New Thread 0x7fffe3efa700 (LWP 5739)]\n[New Thread 0x7fffe36f9700 (LWP 5740)]\n[New Thread 0x7fffe2ef8700 (LWP 5741)]\n[New Thread 0x7fffda9dc700 (LWP 5742)]\nDetaching after fork from child process 5743.\nDetaching after fork from child process 5744.\nDetaching after fork from child process 5745.\nDetaching after fork from child process 5746.\nDetaching after fork from child process 5747.\nDetaching after fork from child process 5813.\nDetaching after fork from child process 5814.\nDetaching after fork from child process 5815.\nDetaching after fork from child process 5818.\nDetaching after fork from child process 5821.\nDetaching after fork from child process 5824.\nDetaching after fork from child process 5827.\nDetaching after fork from child process 5830.\nDetaching after fork from child process 5833.\nDetaching after fork from child process 5836.\nDetaching after fork from child process 5839.\nDetaching after fork from child process 5842.\nDetaching after fork from child process 5845.\nDetaching after fork from child process 5848.\nDetaching after fork from child process 5851.\nDetaching after fork from child process 5854.\nDetaching after fork from child process 5857.\nDetaching after fork from child process 5860.\nDetaching after fork from child process 5863.\nDetaching after fork from child process 5866.\nDetaching after fork from child process 5869.\nDetaching after fork from child process 5872.\nDetaching after fork from child process 5875.\nDetaching after fork from child process 5878.\nDetaching after fork from child process 5881.\nDetaching after fork from child process 5884.\nDetaching after fork from child process 5887.\nDetaching after fork from child process 5890.\nDetaching after fork from child process 5893.\nDetaching after fork from child process 5894.\nDetaching after fork from child process 5895.\nDetaching after fork from child process 5896.\n\nProgram received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 0x7fffda9dc700 (LWP 5742)]\n0x00007ffff74aab4c in virStorageSourceParseBackingURI (path=<optimized out>, src=0x7fffd424bf00) at util/virstoragefile.c:2174\n2174\t    if (VIR_STRDUP(src->path,\nMissing separate debuginfos, use: debuginfo-install audit-libs-2.4.1-1.fc21.x86_64 augeas-libs-1.3.0-1.fc21.x86_64 avahi-libs-0.6.31-30.fc21.x86_64 boost-system-1.55.0-8.fc21.x86_64 boost-thread-1.55.0-8.fc21.x86_64 bzip2-libs-1.0.6-14.fc21.x86_64 cyrus-sasl-gssapi-2.1.26-19.fc21.x86_64 cyrus-sasl-lib-2.1.26-19.fc21.x86_64 cyrus-sasl-md5-2.1.26-19.fc21.x86_64 cyrus-sasl-plain-2.1.26-19.fc21.x86_64 cyrus-sasl-scram-2.1.26-19.fc21.x86_64 dbus-libs-1.8.14-1.fc21.x86_64 device-mapper-libs-1.02.90-1.fc21.x86_64 elfutils-libelf-0.161-2.fc21.x86_64 elfutils-libs-0.161-2.fc21.x86_64 fuse-libs-2.9.3-4.fc21.x86_64 glusterfs-api-3.5.3-1.fc21.x86_64 glusterfs-libs-3.5.3-1.fc21.x86_64 gmp-6.0.0-7.fc21.x86_64 gnutls-3.3.12-1.fc21.x86_64 keyutils-libs-1.5.9-4.fc21.x86_64 libatomic_ops-7.4.2-4.fc21.x86_64 libblkid-2.25.2-2.fc21.x86_64 libcap-ng-0.7.4-7.fc21.x86_64 libcurl-7.37.0-12.fc21.x86_64 libdb-5.3.28-9.fc21.x86_64 libffi-3.1-6.fc21.x86_64 libgcc-4.9.2-1.fc21.x86_64 libgcrypt-1.6.1-7.fc21.x86_64 libgpg-error-1.13-3.fc21.x86_64 libidn-1.28-5.fc21.x86_64 libnl3-3.2.25-5.fc21.x86_64 libpcap-1.6.2-1.fc21.x86_64 libpciaccess-0.13.3-0.3.fc21.x86_64 librados2-0.80.7-3.fc21.x86_64 librbd1-0.80.7-3.fc21.x86_64 libselinux-2.3-5.fc21.x86_64 libsepol-2.3-4.fc21.x86_64 libssh2-1.4.3-16.fc21.x86_64 libstdc++-4.9.2-1.fc21.x86_64 libtasn1-4.2-1.fc21.x86_64 libuuid-2.25.2-2.fc21.x86_64 libwsman1-2.4.6-3.fc21.x86_64 libxml2-2.9.1-6.fc21.x86_64 libxslt-1.1.28-8.fc21.x86_64 netcf-libs-0.2.6-2.fc21.x86_64 nettle-2.7.1-5.fc21.x86_64 nspr-4.10.7-1.fc21.x86_64 nss-3.17.3-2.fc21.x86_64 nss-mdns-0.10-15.fc21.x86_64 nss-softokn-freebl-3.17.3-1.fc21.x86_64 nss-util-3.17.3-1.fc21.x86_64 numactl-libs-2.0.9-4.fc21.x86_64 openldap-2.4.40-2.fc21.x86_64 openssl-libs-1.0.1k-1.fc21.x86_64 p11-kit-0.22.1-1.fc21.x86_64 pcre-8.35-8.fc21.x86_64 python-libs-2.7.8-7.fc21.x86_64 systemd-libs-216-16.fc21.x86_64 trousers-0.3.13-3.fc21.x86_64 xen-libs-4.4.1-12.fc21.x86_64 xz-libs-5.1.2-14alpha.fc21.x86_64 yajl-2.1.0-3.fc21.x86_64 zlib-1.2.8-7.fc21.x86_64\n(gdb) thread apply all bt full\n\nThread 12 (Thread 0x7fffda9dc700 (LWP 5742)):\n#0  0x00007ffff74aab4c in virStorageSourceParseBackingURI (path=<optimized out>, src=0x7fffd424bf00) at util/virstoragefile.c:2174\n        ret = -1\n        uri = 0x7fffd424d1f0\n        scheme = 0x7fffd424eff0\n#1  virStorageSourceNewFromBackingAbsolute (path=<optimized out>) at util/virstoragefile.c:2526\n        ret = 0x7fffd424bf00\n#2  virStorageSourceNewFromBacking (parent=parent@entry=0x7fffd4247ad0) at util/virstoragefile.c:2552\n        st = {st_dev = 140736861158288, st_ino = 0, st_nlink = 64774, st_mode = 2363323, st_uid = 0, st_gid = 1, __pad0 = 0, st_rdev = 33188, st_size = 0, st_blksize = 0, \n          st_blocks = 197632, st_atim = {tv_sec = 4096, tv_nsec = 392}, st_mtim = {tv_sec = 1422971631, tv_nsec = 224412497}, st_ctim = {tv_sec = 1422654908, tv_nsec = 92150077}, \n          __glibc_reserved = {1422654908, 92150077, 0}}\n        ret = <optimized out>\n#3  0x00007fffe10a9895 in virStorageBackendProbeTarget (encryption=0x7fffd424fe98, target=0x7fffd424fe48) at storage/storage_backend_fs.c:99\n        fd = 23\n        ret = -1\n        backingStoreFormat = -1\n        rc = <optimized out>\n        meta = 0x7fffd4247ad0\n        sb = {st_dev = 64774, st_ino = 2363323, st_nlink = 1, st_mode = 33188, st_uid = 0, st_gid = 0, __pad0 = 0, st_rdev = 0, st_size = 197632, st_blksize = 4096, st_blocks = 392, \n          st_atim = {tv_sec = 1422971631, tv_nsec = 224412497}, st_mtim = {tv_sec = 1422654908, tv_nsec = 92150077}, st_ctim = {tv_sec = 1422654908, tv_nsec = 92150077}, \n          __glibc_reserved = {0, 0, 0}}\n#4  virStorageBackendFileSystemRefresh (conn=<optimized out>, pool=0x7fffd40d9530) at storage/storage_backend_fs.c:880\n        dir = 0x7fffd42223c0\n        ent = 0x7fffd4222478\n        sb = {f_bsize = 64774, f_frsize = 2363323, f_blocks = 1, f_bfree = 33188, f_bavail = 0, f_files = 0, f_ffree = 197632, f_favail = 4096, f_fsid = 392, f_flag = 1422971631, \n          f_namemax = 224412497, __f_spare = {1422654908, 0, 92150077, 0, 1422654908, 0}}\n        vol = 0x7fffd424fe10\n        direrr = <optimized out>\n        __FUNCTION__ = \"virStorageBackendFileSystemRefresh\"\n#5  0x00007fffe109e0db in storageDriverAutostart () at storage/storage_driver.c:128\n        pool = 0x7fffd40d9530\n        backend = 0x7fffe12cf500 <virStorageBackendDirectory>\n        started = true\n        i = 1\n        conn = 0x7fffd421b0e0\n        __func__ = \"storageDriverAutostart\"\n#6  0x00007fffe109e3aa in storageStateAutoStart () at storage/storage_driver.c:218\nNo locals.\n#7  0x00007ffff753e37f in virStateInitialize (privileged=true, callback=0x55555556aa70 <daemonInhibitCallback>, opaque=0x5555557ea8f0) at libvirt.c:758\n        i = 3\n        __func__ = \"virStateInitialize\"\n#8  0x000055555556aacb in daemonRunStateInit (opaque=opaque@entry=0x5555557ea8f0) at libvirtd.c:918\n        srv = 0x5555557ea8f0\n        sysident = 0x7fffd4000910\n        __func__ = \"daemonRunStateInit\"\n#9  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n---Type <return> to continue, or q <return> to quit---\n        local = {func = 0x55555556aa90 <daemonRunStateInit>, opaque = 0x5555557ea8f0}\n#10 0x00007ffff42b252a in start_thread (arg=0x7fffda9dc700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffda9dc700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140736861161216, 3769109327082755901, 140737488346113, 4096, 140736861161216, 140736861161920, -3769189847049103555, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#11 0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 11 (Thread 0x7fffe2ef8700 (LWP 5741)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eab78, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de030) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eab78\n        priority = true\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de030}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe2ef8700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe2ef8700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737000736512, 3769109327082755901, 140737488345601, 4096, 140737000736512, 140737000737216, -3769137781308057795, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 10 (Thread 0x7fffe36f9700 (LWP 5740)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eab78, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de1d0) at util/virthreadpool.c:104\n        data = 0x0\n---Type <return> to continue, or q <return> to quit---\n        pool = 0x5555557eaa80\n        cond = 0x5555557eab78\n        priority = true\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de1d0}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe36f9700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe36f9700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737009129216, 3769109327082755901, 140737488345601, 4096, 140737009129216, 140737009129920, -3769136675890849987, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 9 (Thread 0x7fffe3efa700 (LWP 5739)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eab78, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de030) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eab78\n        priority = true\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de030}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe3efa700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe3efa700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737017521920, 3769109327082755901, 140737488345601, 4096, 140737017521920, 140737017522624, -3769135576916093123, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 8 (Thread 0x7fffe46fb700 (LWP 5738)):\n---Type <return> to continue, or q <return> to quit---\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eab78, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de1d0) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eab78\n        priority = true\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de1d0}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe46fb700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe46fb700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737025914624, 3769109327082755901, 140737488345601, 4096, 140737025914624, 140737025915328, -3769134475793852611, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 7 (Thread 0x7fffe4efc700 (LWP 5737)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eab78, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de030) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eab78\n        priority = true\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de030}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe4efc700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe4efc700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737034307328, 3769109327082755901, 140737488345601, 4096, 140737034307328, 140737034308032, -3769133376819095747, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n---Type <return> to continue, or q <return> to quit---\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 6 (Thread 0x7fffe56fd700 (LWP 5736)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eaae0, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de030) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eaae0\n        priority = false\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de030}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe56fd700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe56fd700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737042700032, 3769109327082755901, 140737488345601, 4096, 140737042700032, 140737042700736, -3769132279991822531, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 5 (Thread 0x7fffe5efe700 (LWP 5735)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eaae0, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de1d0) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eaae0\n        priority = false\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de1d0}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe5efe700) at pthread_create.c:310\n        __res = <optimized out>\n---Type <return> to continue, or q <return> to quit---\n        pd = 0x7fffe5efe700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737051092736, 3769109327082755901, 140737488345601, 4096, 140737051092736, 140737051093440, -3769131181017065667, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 4 (Thread 0x7fffe66ff700 (LWP 5734)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eaae0, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de030) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eaae0\n        priority = false\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de030}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe66ff700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe66ff700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737059485440, 3769109327082755901, 140737488345601, 4096, 140737059485440, 140737059486144, -3769130079894825155, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 3 (Thread 0x7fffe6f00700 (LWP 5733)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eaae0, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de1d0) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eaae0\n        priority = false\n---Type <return> to continue, or q <return> to quit---\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de1d0}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe6f00700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe6f00700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737067878144, 3769109327082755901, 140737488345601, 4096, 140737067878144, 140737067878848, -3769128980920068291, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 2 (Thread 0x7fffe7701700 (LWP 5732)):\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\nNo locals.\n#1  0x00007ffff74b04b6 in virCondWait (c=c@entry=0x5555557eaae0, m=m@entry=0x5555557eaab8) at util/virthread.c:153\n        ret = <optimized out>\n#2  0x00007ffff74b096b in virThreadPoolWorker (opaque=opaque@entry=0x5555557de1d0) at util/virthreadpool.c:104\n        data = 0x0\n        pool = 0x5555557eaa80\n        cond = 0x5555557eaae0\n        priority = false\n        job = 0x0\n#3  0x00007ffff74b026e in virThreadHelper (data=<optimized out>) at util/virthread.c:197\n        args = 0x0\n        local = {func = 0x7ffff74b0780 <virThreadPoolWorker>, opaque = 0x5555557de1d0}\n#4  0x00007ffff42b252a in start_thread (arg=0x7fffe7701700) at pthread_create.c:310\n        __res = <optimized out>\n        pd = 0x7fffe7701700\n        now = <optimized out>\n        unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140737076270848, 3769109327082755901, 140737488345601, 4096, 140737076270848, 140737076271552, -3769127961402206403, \n                -3769098780620941507}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n        not_first_call = <optimized out>\n        pagesize_m1 = <optimized out>\n        sp = <optimized out>\n        freesize = <optimized out>\n#5  0x00007ffff3fee79d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\nNo locals.\n\nThread 1 (Thread 0x7ffff7f82880 (LWP 5728)):\n#0  0x00007ffff3fe31fd in poll () at ../sysdeps/unix/syscall-template.S:81\nNo locals.\n#1  0x00007ffff7474b82 in poll (__timeout=-1, __nfds=7, __fds=<optimized out>) at /usr/include/bits/poll2.h:46\n---Type <return> to continue, or q <return> to quit---\nNo locals.\n#2  virEventPollRunOnce () at util/vireventpoll.c:641\n        fds = 0x555555806720\n        ret = <optimized out>\n        timeout = -1\n        nfds = 7\n        __func__ = \"virEventPollRunOnce\"\n        __FUNCTION__ = \"virEventPollRunOnce\"\n#3  0x00007ffff74737b1 in virEventRunDefaultImpl () at util/virevent.c:308\n        __func__ = \"virEventRunDefaultImpl\"\n#4  0x000055555559a84d in virNetServerRun (srv=0x5555557ea8f0) at rpc/virnetserver.c:1139\n        timerid = -1\n        timerActive = false\n        i = <optimized out>\n        __FUNCTION__ = \"virNetServerRun\"\n        __func__ = \"virNetServerRun\"\n#5  0x000055555556a86b in main (argc=<optimized out>, argv=<optimized out>) at libvirtd.c:1503\n        srv = 0x5555557ea8f0\n        remote_config_file = 0x5555557ea360 \"/etc/libvirt/libvirtd.conf\"\n        statuswrite = -1\n        ret = 1\n        pid_file_fd = 5\n        pid_file = 0x5555557ea5b0 \"/var/run/libvirtd.pid\"\n        sock_file = 0x5555557f6250 \"/var/run/libvirt/libvirt-sock\"\n        sock_file_ro = 0x5555557f6220 \"/var/run/libvirt/libvirt-sock-ro\"\n        timeout = -1\n        verbose = 0\n        godaemon = 0\n        ipsock = 0\n        config = 0x5555557e48a0\n        privileged = <optimized out>\n        implicit_conf = <optimized out>\n        run_dir = 0x5555557ea540 \"/var/run/libvirt\"\n        old_umask = <optimized out>\n        opts = {{name = 0x55555559d4de \"verbose\", has_arg = 0, flag = 0x7fffffffdd28, val = 118}, {name = 0x55555559d4e6 \"daemon\", has_arg = 0, flag = 0x7fffffffdd2c, val = 100}, {\n            name = 0x55555559d4ed \"listen\", has_arg = 0, flag = 0x7fffffffdd30, val = 108}, {name = 0x55555559d5f5 \"config\", has_arg = 1, flag = 0x0, val = 102}, {\n            name = 0x55555559d555 \"timeout\", has_arg = 1, flag = 0x0, val = 116}, {name = 0x55555559d4f4 \"pid-file\", has_arg = 1, flag = 0x0, val = 112}, {name = 0x55555559d4fd \"version\", \n            has_arg = 0, flag = 0x0, val = 86}, {name = 0x55555559d505 \"help\", has_arg = 0, flag = 0x0, val = 104}, {name = 0x0, has_arg = 0, flag = 0x0, val = 0}}\n        __func__ = \"main\"\n(gdb)"
					},
					{
						"isprivate": "0",
						"commentid": "7904477",
						"comment_count": "3",
						"who": {
							"text": "kchamart",
							"name": "Kashyap Chamarthy"
						},
						"bug_when": "2015-02-03 16:09:50 +0000",
						"thetext": "Some additional information\n---------------------------\n\n$ for i in `find /var/lib/libvirt/images`; do qemu-img  info $i | grep \"backing file:\"; done\nbacking file: nbd://localhost\nbacking file: ./cirros-0.3.3-x86_64-disk.img (actual path: /var/lib/libvirt/images/./cirros-0.3.3-x86_64-disk.img)\nbacking file: nbd://localhost\nbacking file: nbd://localhost\nbacking file: nbd://localhost\n\n\n\nA related thread with upstream QEMU, where QEMU segfaults when booting an overlay with backing_file hosted over NBD: nbd.c:nbd_receive_request():L756: read failed\n\n  http://lists.nongnu.org/archive/html/qemu-devel/2015-01/msg04397.html\n\n\nThe root cause is identified here:\n\n  http://lists.nongnu.org/archive/html/qemu-devel/2015-01/msg04700.html"
					},
					{
						"isprivate": "0",
						"commentid": "7904691",
						"comment_count": "4",
						"who": {
							"text": "pkrempa",
							"name": "Peter Krempa"
						},
						"bug_when": "2015-02-03 17:11:52 +0000",
						"thetext": "Proposed patch:\nhttp://www.redhat.com/archives/libvir-list/2015-February/msg00063.html"
					},
					{
						"isprivate": "0",
						"commentid": "7906486",
						"comment_count": "5",
						"who": {
							"text": "pkrempa",
							"name": "Peter Krempa"
						},
						"bug_when": "2015-02-04 07:47:54 +0000",
						"thetext": "commit fdb80ed4f6563928b9942a0d1450e0c725aa6c06\nAuthor: Peter Krempa <pkrempa@redhat.com>\nDate:   Tue Feb 3 18:03:41 2015 +0100\n\n    util: storage: Fix parsing of nbd:// URI without path\n    \n    If a storage file would be backed with a NBD device without path\n    (nbd://localhost) libvirt would crash when parsing the backing path for\n    the disk as the URI structure's path element is NULL in such case but\n    the NBD parser would access it shamelessly.\n\nv1.2.12-74-gfdb80ed"
					},
					{
						"isprivate": "0",
						"commentid": "7917097",
						"comment_count": "6",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-08 16:34:11 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been submitted as an update for Fedora 21.\nhttps://admin.fedoraproject.org/updates/libvirt-1.2.9.2-1.fc21"
					},
					{
						"isprivate": "0",
						"commentid": "7918209",
						"comment_count": "7",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-09 05:32:05 +0000",
						"thetext": "Package libvirt-1.2.9.2-1.fc21:\n* should fix your issue,\n* was pushed to the Fedora 21 testing repository,\n* should be available at your local mirror within two days.\nUpdate it with:\n# su -c 'yum update --enablerepo=updates-testing libvirt-1.2.9.2-1.fc21'\nas soon as you are able to.\nPlease go to the following url:\nhttps://admin.fedoraproject.org/updates/FEDORA-2015-1892/libvirt-1.2.9.2-1.fc21\nthen log in and leave karma (feedback)."
					},
					{
						"isprivate": "0",
						"commentid": "7938338",
						"comment_count": "8",
						"who": {
							"text": "updates",
							"name": "Fedora Update System"
						},
						"bug_when": "2015-02-15 03:06:15 +0000",
						"thetext": "libvirt-1.2.9.2-1.fc21 has been pushed to the Fedora 21 stable repository.  If problems still persist, please make note of it in this bug report."
					}
				]
			}
		}
	],
	"builds": [
		{
			"nvr": "libvirt-1.2.9.2-1.fc21",
			"signed": true,
			"type": "rpm",
			"package": {
				"armv7hl": [
					{
						"name": "libvirt-docs",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-client",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-secret",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-interface",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-qemu",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-devel",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-lxc",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-network",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-qemu",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-config-nwfilter",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-uml",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-storage",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-nwfilter",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-kvm",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-nodedev",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-wireshark",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-uml",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-lock-sanlock",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-config-network",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-login-shell",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-daemon-driver-lxc",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					},
					{
						"name": "libvirt-debuginfo",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "armv7hl"
					}
				],
				"i686": [
					{
						"name": "libvirt-daemon-driver-qemu",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-secret",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-uml",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-login-shell",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-wireshark",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-config-network",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-interface",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-nwfilter",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-config-nwfilter",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-storage",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-nodedev",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-docs",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-debuginfo",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-network",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-kvm",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-vbox",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-client",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-vbox",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-lxc",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-lxc",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-xen",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-xen",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-uml",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-qemu",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon-driver-libxl",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-lock-sanlock",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-devel",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					},
					{
						"name": "libvirt-daemon",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "i686"
					}
				],
				"src": [
					{
						"name": "libvirt",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "src"
					}
				],
				"x86_64": [
					{
						"name": "libvirt-daemon-driver-storage",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-config-nwfilter",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-wireshark",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-lxc",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-lxc",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-vbox",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-uml",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-uml",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-xen",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-debuginfo",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-network",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-devel",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-nwfilter",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-docs",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-libxl",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-xen",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-client",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-qemu",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-lock-sanlock",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-kvm",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-qemu",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-vbox",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-secret",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-login-shell",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-interface",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-driver-nodedev",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					},
					{
						"name": "libvirt-daemon-config-network",
						"version": "1.2.9.2",
						"release": "1.fc21",
						"arch": "x86_64"
					}
				]
			}
		}
	],
	"close_bugs": true,
	"comments": [
		{
			"id": 179003,
			"text": "This update has been submitted for testing by crobinso. ",
			"timestamp": "2015-02-08 16:34:35",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179004,
			"text": "Taskotron: depcheck test PASSED on i386. Result log:\nhttps://taskotron.fedoraproject.org/taskmaster//builders/x86_64/builds/35492/steps/runtask/logs/stdio\n(results are informative only)",
			"timestamp": "2015-02-08 17:00:53",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/1c99e8328b68b58a71f5a9d6449baa7cb914591c56cbec0adfac7c50e4abefa4?s=24&d=retro",
				"email": "taskotron@fedoraproject.org",
				"groups": [
					{}
				],
				"id": 100,
				"name": "taskotron",
				"openid": "taskotron.id.fedoraproject.org"
			},
			"user_id": 100
		},
		{
			"id": 179005,
			"text": "Taskotron: depcheck test PASSED on x86_64. Result log:\nhttps://taskotron.fedoraproject.org/taskmaster//builders/x86_64/builds/35492/steps/runtask/logs/stdio\n(results are informative only)",
			"timestamp": "2015-02-08 17:04:44",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/1c99e8328b68b58a71f5a9d6449baa7cb914591c56cbec0adfac7c50e4abefa4?s=24&d=retro",
				"email": "taskotron@fedoraproject.org",
				"groups": [
					{}
				],
				"id": 100,
				"name": "taskotron",
				"openid": "taskotron.id.fedoraproject.org"
			},
			"user_id": 100
		},
		{
			"id": 179006,
			"text": "This update is currently being pushed to the Fedora 21 testing updates repository.",
			"timestamp": "2015-02-08 18:43:43",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179007,
			"text": "This update has been pushed to testing",
			"timestamp": "2015-02-09 05:32:21",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179008,
			"karma": 1,
			"text": "VMs seems to work for me",
			"timestamp": "2015-02-10 01:20:24",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/b69a781f897ff47fb3d40e9bd36309fb6d6aecb6892aa07fbcf302de054e5b12?s=24&d=retro",
				"email": "nonamedotc@gmail.com",
				"groups": [
					{
						"name": "qa"
					},
					{
						"name": "packager"
					},
					{
						"name": "provenpackager"
					},
					{
						"name": "ipausers"
					},
					{
						"name": "fedora-contributor"
					},
					{
						"name": "signed_fpca"
					},
					{
						"name": "fedorabugs"
					},
					{
						"name": "scitech_sig"
					},
					{
						"name": "triagers"
					}
				],
				"id": 306,
				"name": "nonamedotc",
				"openid": "nonamedotc.id.fedoraproject.org"
			},
			"user_id": 306
		},
		{
			"id": 179009,
			"karma": 1,
			"text": "no problems spotted",
			"timestamp": "2015-02-12 08:29:55",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/361588cc461dac33122e97f93df9b46d5401fc7f59e4be843887319b1f5be103?s=24&d=retro",
				"email": "jpopelka@redhat.com",
				"groups": [
					{
						"name": "packager"
					},
					{
						"name": "communishift"
					},
					{
						"name": "gitpysmbc"
					},
					{
						"name": "ipausers"
					},
					{
						"name": "gitfirewalld-recode"
					},
					{
						"name": "signed_fpca"
					},
					{
						"name": "gitsystem-config-network"
					},
					{
						"name": "git-packit-team"
					},
					{
						"name": "fedora-contributor"
					},
					{
						"name": "fedorabugs"
					},
					{
						"name": "gitpython-iwlib"
					},
					{
						"name": "gitsystem-config-printer"
					},
					{
						"name": "gitdhcpv6"
					},
					{
						"name": "gitpycups"
					},
					{
						"name": "gitfirewalld"
					},
					{
						"name": "fedora-ci-admins"
					},
					{
						"name": "atomic-ci"
					}
				],
				"id": 122,
				"name": "jpopelka",
				"openid": "jpopelka.id.fedoraproject.org"
			},
			"user_id": 122
		},
		{
			"id": 179010,
			"karma": 1,
			"text": "yeah existing VM's are fine with this update",
			"timestamp": "2015-02-13 03:19:26",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/8565c2dfa53d10789f72ad8acb147dcde3c431f668cde1916a812d1d8f945875?s=24&d=retro",
				"email": "pnemade@redhat.com",
				"groups": [
					{
						"name": "provenpackager"
					},
					{
						"name": "packager"
					},
					{
						"name": "giti18n"
					},
					{
						"name": "gitinscript2"
					},
					{
						"name": "gitwordxtr"
					},
					{
						"name": "gityum-langpacks"
					},
					{
						"name": "svnsystem-config-language"
					},
					{
						"name": "ipausers"
					},
					{
						"name": "gitutrrs-web"
					},
					{
						"name": "svnlohit"
					},
					{
						"name": "fedora-contributor"
					},
					{
						"name": "svniok"
					},
					{
						"name": "fedorabugs"
					},
					{
						"name": "signed_fpca"
					},
					{
						"name": "gitiok2"
					},
					{
						"name": "gitfontpackages"
					},
					{
						"name": "gitredhatlsb"
					},
					{
						"name": "cla_redhat"
					},
					{
						"name": "cvslohit-fonts"
					},
					{
						"name": "trust admins"
					}
				],
				"id": 262,
				"name": "pnemade",
				"openid": "pnemade.id.fedoraproject.org"
			},
			"user_id": 262
		},
		{
			"id": 179011,
			"text": "This update has reached the stable karma threshold and will be pushed to the stable updates repository",
			"timestamp": "2015-02-13 03:19:31",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179012,
			"text": "Taskotron: upgradepath test PASSED on noarch. Result log:\nhttps://taskotron.fedoraproject.org/taskmaster//builders/x86_64/builds/36935/steps/runtask/logs/stdio\n(results are informative only)",
			"timestamp": "2015-02-13 09:46:11",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/1c99e8328b68b58a71f5a9d6449baa7cb914591c56cbec0adfac7c50e4abefa4?s=24&d=retro",
				"email": "taskotron@fedoraproject.org",
				"groups": [
					{}
				],
				"id": 100,
				"name": "taskotron",
				"openid": "taskotron.id.fedoraproject.org"
			},
			"user_id": 100
		},
		{
			"id": 179013,
			"text": "This update is currently being pushed to the Fedora 21 stable updates repository.",
			"timestamp": "2015-02-14 03:19:19",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179014,
			"text": "This update is currently being pushed to the Fedora 21 stable updates repository.",
			"timestamp": "2015-02-14 03:30:32",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179015,
			"text": "Taskotron: depcheck test FAILED on x86_64. Result log:\nhttps://taskotron.fedoraproject.org/taskmaster//builders/x86_64/builds/37229/steps/runtask/logs/stdio\n(results are informative only)",
			"timestamp": "2015-02-14 03:55:31",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/1c99e8328b68b58a71f5a9d6449baa7cb914591c56cbec0adfac7c50e4abefa4?s=24&d=retro",
				"email": "taskotron@fedoraproject.org",
				"groups": [
					{}
				],
				"id": 100,
				"name": "taskotron",
				"openid": "taskotron.id.fedoraproject.org"
			},
			"user_id": 100
		},
		{
			"id": 179016,
			"text": "Automatic push to stable based on karma has been disabled for this update due to failure of an AutoQA test. Update submitter, please check the AutoQA test result and see if there is a valid problem to be fixed here, and fix it if so. If the failure is a mistake on AutoQA's part, you can re-enable the automatic push feature for this update if you like, or push it stable manually once it reaches the requirements under the Updates Policy.",
			"timestamp": "2015-02-14 03:55:33",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179017,
			"text": "Claims a whole bunch of things have broken deps, I think it's some other problem\nand not libvirt's fault.",
			"timestamp": "2015-02-14 20:10:02",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/2db9913ea72f8be4fb00bf87f927f22b40a6c3b348f68abbabdf4d1a93ff09af?s=24&d=retro",
				"email": "crobinso@redhat.com",
				"groups": [
					{
						"name": "packager"
					},
					{
						"name": "provenpackager"
					},
					{
						"name": "virtmaint-sig"
					},
					{
						"name": "ipausers"
					},
					{
						"name": "fedora-contributor"
					},
					{
						"name": "signed_fpca"
					},
					{
						"name": "fedorabugs"
					},
					{
						"name": "hosted-content"
					},
					{
						"name": "kubevirt"
					}
				],
				"id": 400,
				"name": "crobinso",
				"openid": "crobinso.id.fedoraproject.org"
			},
			"user_id": 400
		},
		{
			"id": 179018,
			"text": "This update has been pushed to stable",
			"timestamp": "2015-02-15 03:07:02",
			"update_id": 23424,
			"user": {
				"avatar": "https://apps.fedoraproject.org/img/icons/bodhi-24.png",
				"id": 91,
				"name": "bodhi",
				"openid": "bodhi.id.fedoraproject.org"
			},
			"user_id": 91
		},
		{
			"id": 179019,
			"karma": 1,
			"timestamp": "2015-02-15 04:39:56",
			"update_id": 23424,
			"user": {
				"avatar": "https://seccdn.libravatar.org/avatar/e04beb63c279ac05f99dd5ea1252e8d45b15611d1a9226bc42bda9fb31f24c75?s=24&d=retro",
				"email": "i@cicku.me",
				"groups": [
					{
						"name": "packager"
					}
				],
				"id": 120,
				"name": "cicku",
				"openid": "cicku.id.fedoraproject.org"
			},
			"user_id": 120
		}
	],
	"content_type": "rpm",
	"date_pushed": "2015-02-15 03:07:02",
	"date_stable": "2015-02-15 03:07:02",
	"date_submitted": "2015-02-08 16:34:03",
	"date_testing": "2015-02-09 05:32:21",
	"karma": 4,
	"meets_testing_requirements": true,
	"notes": "* Rebased to version 1.2.9.2\n* CVE-2014-8131: deadlock and segfault in qemuConnectGetAllDomainStats (bz #1172571)\n* CVE-2015-0236: missing ACL check for the VIR_DOMAIN_XML_SECURE flag in save images and snapshots objects (bz #1185769)\n* CVE-2014-8136: local denial of service in qemu/qemu_driver.c (bz #1176179)\n* Fix crash parsing nbd URIs (bz #1188644)\n* Fix domain startup failing with 'strict' mode in numatune (bz #1168672)",
	"pushed": true,
	"release": {
		"branch": "f21",
		"candidate_tag": "f21-updates-candidate",
		"composed_by_bodhi": true,
		"dist_tag": "f21",
		"id_prefix": "FEDORA",
		"long_name": "Fedora 21",
		"mail_template": "fedora_errata_template",
		"name": "F21",
		"override_tag": "f21-override",
		"package_manager": "dnf",
		"pending_stable_tag": "f21-updates-pending",
		"pending_testing_tag": "f21-updates-testing-pending",
		"stable_tag": "f21-updates",
		"state": "archived",
		"testing_repository": "updates-testing",
		"testing_tag": "f21-updates-testing",
		"version": "21"
	},
	"severity": "unspecified",
	"stable_karma": 3,
	"status": "stable",
	"suggest": "unspecified",
	"title": "libvirt-1.2.9.2-1.fc21",
	"type": "security",
	"url": "https://bodhi.fedoraproject.org/updates/FEDORA-2015-1892",
	"unstable_karma": -3,
	"updateid": "FEDORA-2015-1892",
	"user": {
		"avatar": "https://seccdn.libravatar.org/avatar/2db9913ea72f8be4fb00bf87f927f22b40a6c3b348f68abbabdf4d1a93ff09af?s=24&d=retro",
		"email": "crobinso@redhat.com",
		"groups": [
			{
				"name": "packager"
			},
			{
				"name": "provenpackager"
			},
			{
				"name": "virtmaint-sig"
			},
			{
				"name": "ipausers"
			},
			{
				"name": "fedora-contributor"
			},
			{
				"name": "signed_fpca"
			},
			{
				"name": "fedorabugs"
			},
			{
				"name": "hosted-content"
			},
			{
				"name": "kubevirt"
			}
		],
		"id": 400,
		"name": "crobinso",
		"openid": "crobinso.id.fedoraproject.org"
	},
	"version_hash": "32a40fb67d565b5c8e633c7b7117d53a813452f8"
}
